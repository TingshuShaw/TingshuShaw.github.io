<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    
<script src="https://raw.githubusercontent.com/HubSpot/pace/v1.0.2/pace.min.js"></script>

    
<link rel="stylesheet" href="https://github.com/HubSpot/pace/raw/master/themes/orange/pace-theme-flash.css">

  
  

  <!-- PACE Progress Bar START -->

  
  <title>hadoop——mapreduce学习 | Shaw</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Hadoop" />
  
  
  
  
  <meta name="description" content="本章从MapReduce的原理、工作机制、应用开发、设计模式、算法时间和性能调优进行了详细的介绍 目标： 1、了解MapReduce原理(map函数、reduce函数、shuffle过程) 2、掌握MapReduce相关算法 所有实例的数据&amp;依赖包hadoop2lib.tar.gz——百度云链接  提取码：hsxq">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop——MapReduce学习">
<meta property="og:url" content="http://yoursite.com/2020/03/26/BigData/Hadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Shaw">
<meta property="og:description" content="本章从MapReduce的原理、工作机制、应用开发、设计模式、算法时间和性能调优进行了详细的介绍 目标： 1、了解MapReduce原理(map函数、reduce函数、shuffle过程) 2、掌握MapReduce相关算法 所有实例的数据&amp;依赖包hadoop2lib.tar.gz——百度云链接  提取码：hsxq">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/12.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e213b2a-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="f:%5CMy_Study%5CBlog_Shaw%5CmyBlog%5Csource_posts%5CBigData%5CHadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0%5C2.1.PNG">
<meta property="og:image" content="f:%5CMy_Study%5CBlog_Shaw%5CmyBlog%5Csource_posts%5CBigData%5CHadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0%5C2.2.PNG">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e30f996-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e3fa46d-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e693f7d-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-1.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-2.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/01.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/02.jpg">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/03.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/04.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/05.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/06.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/07.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/08.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/09.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/10.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/11.png">
<meta property="og:image" content="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/12.png">
<meta property="article:published_time" content="2020-03-26T00:51:50.000Z">
<meta property="article:modified_time" content="2020-03-31T07:14:38.323Z">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/01.png">
  
    <link rel="alternate" href="/atom.xml" title="Shaw" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="https://cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css" >
  <link rel="stylesheet" href="/css/hiero.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >
  

  <!-- Custom CSS -->
  
<link rel="stylesheet" href="/css/my.css">

  <!-- Google Adsense -->
  
<meta name="generator" content="Hexo 4.2.0"></head>

<script>
var themeMenus = {};

  themeMenus["/"] = "Home"; 

  themeMenus["/archives"] = "Archives"; 

  themeMenus["/categories"] = "Categories"; 

  themeMenus["/tags"] = "Tags"; 

  themeMenus["/about"] = "About"; 

</script>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  <header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" rel="home" >
                <img style="margin-bottom: 10px;"  width="124px" height="124px" alt="Hike News" src="http://h.hiphotos.baidu.com/zhidao/wh%3D450%2C600/sign=0b995d383f292df59796a41189017056/d8f9d72a6059252d4b5d8513319b033b5bb5b95b.jpg">
              </a>
            
          </h1>

          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">Home</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">Archives</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">Categories</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">Tags</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">About</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=128299422,1502359480&fm=26&gp=0.jpg".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-BigData/Hadoop——MapReduce学习" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      Hadoop——MapReduce学习
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2020/03/26/BigData/Hadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0/" class="article-date">
	  <time datetime="2020-03-26T00:51:50.000Z" itemprop="datePublished">March 26, 2020</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>本章从MapReduce的原理、工作机制、应用开发、设计模式、算法时间和性能调优进行了详细的介绍</p>
<p>目标：</p>
<p>1、了解MapReduce原理(map函数、reduce函数、shuffle过程)</p>
<p>2、掌握MapReduce相关算法</p>
<p><a href="https://pan.baidu.com/s/1BnCF_l5cLYbj5d0PyKm6nA" target="_blank" rel="noopener">所有实例的数据&amp;依赖包hadoop2lib.tar.gz——百度云链接 </a></p>
<p>提取码：hsxq</p>
<a id="more"></a>

<h5 id="MapReduce学习——习题"><a href="#MapReduce学习——习题" class="headerlink" title="MapReduce学习——习题"></a>MapReduce学习——习题</h5><p>1.对MapReduce的体系结构，以下说法正确的是：</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <p>A.分布式编程架构</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>B.以数据为中心，更看重吞吐量</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>C.分而治之的思想</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>D.将一个任务分解成多个任务</p>
</li>
</ul>
<p>2.MapReduce为了保证任务的正常执行，采用（）等多种容错机制</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <p>A.重复执行</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>B.重新开始整个任务</p>
</li>
<li><input disabled="" type="checkbox"> <p>C.推测执行</p>
</li>
<li><input disabled="" type="checkbox"> <p>D.直接丢弃执行效率低的作业</p>
</li>
</ul>
<p>3.对Hadoop中JobTacker的工作角色，以下说法正确的是（）</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <p>A.作业调度</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>B.分配任务</p>
</li>
<li><input disabled="" type="checkbox"> <p>C.监控CPU运行效率</p>
</li>
<li><input checked="" disabled="" type="checkbox"> <p>D.监控任务执行进度</p>
</li>
</ul>
<p>4.在Hadoop中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker的负责作业的分解、状态监控以及资源管理</p>
<p>5.Map的主要工作是将任务分解成多个任务</p>
<h5 id="MapReduce实例——WordCount"><a href="#MapReduce实例——WordCount" class="headerlink" title="MapReduce实例——WordCount"></a>MapReduce实例——WordCount</h5><h6 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h6><p>1.准确理解Mapreduce的设计原理</p>
<p>2.熟练掌握WordCount程序代码编写</p>
<p>3.学会自己编写WordCount程序进行词频统计</p>
<h6 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h6><p>MapReduce采用的是“分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个从节点共同完成，然后通过整合各个节点的中间结果，得到最终结果。简单来说，MapReduce就是”任务的分解与结果的汇总“。</p>
<p>1.MapReduce的工作原理</p>
<p>在分布式计算中，MapReduce框架负责处理了并行编程里分布式存储、工作调度，负载均衡、容错处理以及网络通信等复杂问题，现在我们把处理过程高度抽象为Map与Reduce两个部分来进行阐述，其中Map部分负责把任务分解成多个子任务，Reduce部分负责把分解后多个子任务的处理结果汇总起来，具体设计思路如下。</p>
<p>（1）Map过程需要继承org.apache.hadoop.mapreduce包中Mapper类，并重写其map方法。通过在map方法中添加两句把key值和value值输出到控制台的代码，可以发现map方法中输入的value值存储的是文本文件中的一行（以回车符为行结束标记），而输入的key值存储的是该行的首字母相对于文本文件的首地址的偏移量。然后用StringTokenizer类将每一行拆分成为一个个的字段，把截取出需要的字段（本实验为买家id字段）设置为key，并将其作为map方法的结果输出。</p>
<p>（2）Reduce过程需要继承org.apache.hadoop.mapreduce包中Reducer类，并重写其reduce方法。Map过程输出的&lt;key,value&gt;键值对先经过shuffle过程把key值相同的所有value值聚集起来形成values，此时values是对应key字段的计数值所组成的列表，然后将&lt;key,values&gt;输入到reduce方法中，reduce方法只要遍历values并求和，即可得到某个单词的总次数。</p>
<p>在main()主函数中新建一个Job对象，由Job对象负责管理和运行MapReduce的一个计算任务，并通过Job的一些方法对任务的参数进行相关的设置。本实验是设置使用将继承Mapper的doMapper类完成Map过程中的处理和使用doReducer类完成Reduce过程中的处理。还设置了Map过程和Reduce过程的输出类型：key的类型为Text，value的类型为IntWritable。任务的输出和输入路径则由字符串指定，并由FileInputFormat和FileOutputFormat分别设定。完成相应任务的参数设定后，即可调用job.waitForCompletion()方法执行任务，其余的工作都交由MapReduce框架处理。</p>
<p>2.MapReduce框架的作业运行流程</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<p>（1）ResourceManager：是YARN资源控制框架的中心模块，负责集群中所有资源的统一管理和分配。它接收来自NM(NodeManager)的汇报，建立AM，并将资源派送给AM(ApplicationMaster)。</p>
<p>（2）NodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器管理，并监控他们的资源使用情况（cpu、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。</p>
<p>（3）ApplicationMaster：以下简称AM。YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动Container，并告诉Container做什么事情。</p>
<p>（4）Container：资源容器。YARN中所有的应用都是在Container之上运行的。AM也是在Container上运行的，不过AM的Container是RM申请的。Container是YARN中资源的抽象，它封装了某个节点上一定量的资源（CPU和内存两类资源）。Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster。Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令（可以是任何命令，比如java、Python、C++进程启动命令均可）以及该命令执行所需的环境变量和外部资源（比如词典文件、可执行文件、jar包等）。</p>
<p>另外，一个应用程序所需的Container分为两大类，如下：</p>
<p>①运行ApplicationMaster的Container：这是由ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的ApplicationMaster所需的资源。</p>
<p>②运行各类任务的Container：这是由ApplicationMaster向ResourceManager申请的，并为了ApplicationMaster与NodeManager通信以启动的。</p>
<p>以上两类Container可能在任意节点上，它们的位置通常而言是随机的，即ApplicationMaster可能与它管理的任务运行在一个节点上。</p>
<h6 id="任务步骤"><a href="#任务步骤" class="headerlink" title="任务步骤"></a>任务步骤</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#step1: 启动Hadoop</span><br><span class="line"></span><br><span class="line">#step2: 创建目录，下载数据文件</span><br><span class="line"></span><br><span class="line">#step3: 将linux本地&#x2F;data&#x2F;mapreduce1&#x2F;buyer_favorite1，上传到HDFS上的&#x2F;mymapreduce1&#x2F;in目录下</span><br><span class="line">hadoop fs -mkdir -p &#x2F;mymapreduce1&#x2F;in  </span><br><span class="line">hadoop fs -put &#x2F;data&#x2F;mapreduce1&#x2F;buyer_favorite1 &#x2F;mymapreduce1&#x2F;in  </span><br><span class="line"></span><br><span class="line">#step4: 打开Eclipse，新建Java Project项目,并将项目名设置为mapreduce1;在项目名mapreduce1下，新建package包,并将包命名为mapreduce;在创建的包mapreduce下，新建类,并将类命名为WordCount.</span><br><span class="line"></span><br><span class="line">#step5: 添加项目所需依赖的jar包,右键单击项目名，新建一个目录hadoop2lib，用于存放项目所需的jar包。</span><br><span class="line"></span><br><span class="line">#step6: 编写Java代码</span><br><span class="line"></span><br><span class="line">#step7: 在WordCount类文件中，单击右键&#x3D;&gt;Run As&#x3D;&gt;Run on Hadoop选项，将MapReduce任务提交到Hadoop中</span><br><span class="line"></span><br><span class="line">#step8: 待执行完毕后，打开终端或使用hadoop eclipse插件，查看hdfs上，程序输出的实验结果</span><br><span class="line">hadoop fs -ls &#x2F;mymapreduce1&#x2F;out  </span><br><span class="line">hadoop fs -cat &#x2F;mymapreduce1&#x2F;out&#x2F;part-r-00000</span><br></pre></td></tr></table></figure>

<p><img src="https://insight.ipieuvre.com/doc/exper/1e146ce6-91ad-11e9-beeb-00215ec892f4/img/12.png" alt="img"></p>
<p>完整代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;  </span><br><span class="line">        Job job = Job.getInstance();  </span><br><span class="line">        job.setJobName(<span class="string">"WordCount"</span>);  </span><br><span class="line">        job.setJarByClass(WordCount<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setMapperClass(doMapper<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setReducerClass(doReducer<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        Path in = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce1/in/buyer_favorite1"</span>);  </span><br><span class="line">        Path out = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce1/out"</span>);  </span><br><span class="line">        FileInputFormat.addInputPath(job, in);  </span><br><span class="line">        FileOutputFormat.setOutputPath(job, out);  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">doMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Text word = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span>  </span></span><br><span class="line"><span class="function">                    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">            StringTokenizer tokenizer = <span class="keyword">new</span> StringTokenizer(value.toString(), <span class="string">"\t"</span>);  </span><br><span class="line">                word.set(tokenizer.nextToken());  </span><br><span class="line">                context.write(word, one);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">doReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span>  </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;  </span><br><span class="line">        sum += value.get();  </span><br><span class="line">        &#125;  </span><br><span class="line">        result.set(sum);  </span><br><span class="line">        context.write(key, result);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——去重"><a href="#MapReduce实例——去重" class="headerlink" title="MapReduce实例——去重"></a>MapReduce实例——去重</h5><h6 id="任务目标-1"><a href="#任务目标-1" class="headerlink" title="任务目标"></a>任务目标</h6><p>1.准确理解MapReduce去重的设计原理</p>
<p>2.熟练掌握MapReduce去重的程序编写</p>
<p>3.学会自己编写MapReduce去重代码解决实际问题</p>
<h6 id="相关知识-1"><a href="#相关知识-1" class="headerlink" title="相关知识"></a>相关知识</h6><p>“数据去重”主要是为了掌握和利用并行化思想来对数据进行有意义的筛选。统计大数据集上的数据种类个数、从网站日志中计算访问地等这些看似庞杂的任务都会涉及数据去重。</p>
<p>数据去重的最终目标是让原始数据中出现次数超过一次的数据在输出文件中只出现一次。在MapReduce流程中，map的输出&lt;key,value&gt;经过shuffle过程聚集成&lt;key,value-list&gt;后交给reduce。我们自然而然会想到将同一个数据的所有记录都交给一台reduce机器，无论这个数据出现多少次，只要在最终结果中输出一次就可以了。具体就是reduce的输入应该以数据作为key，而对value-list则没有要求（可以设置为空）。当reduce接收到一个&lt;key,value-list&gt;时就直接将输入的key复制到输出的key中，并将value设置成空值，然后输出&lt;key,value&gt;。</p>
<p>MaprReduce去重流程如下图所示：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e213b2a-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e213b2a-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<h6 id="任务内容"><a href="#任务内容" class="headerlink" title="任务内容"></a>任务内容</h6><p>现有一个某电商网站的数据文件，名为buyer_favorite1，记录了用户收藏的商品以及收藏的日期，文件buyer_favorite1中包含（用户id，商品id，收藏日期）三个字段，数据内容以“\t”分割，要求用Java编写MapReduce程序，根据商品id进行去重，统计用户收藏商品中都有哪些商品被收藏。</p>
<h6 id="任务步骤-1"><a href="#任务步骤-1" class="headerlink" title="任务步骤"></a>任务步骤</h6><p>1.启动Hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">切换到hadoop的sbin目录下</span></span><br><span class="line">cd /apps/hadoop/sbin</span><br><span class="line"><span class="meta">#</span><span class="bash">启动Hadoop</span></span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>

<p>2.新建目录，下载数据包并下载和解压依赖包hadoop2lib.tar.gz</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">新建目录是为了方便进行项目数据的整理</span></span><br><span class="line">mkdir -p /data/mapreduce2</span><br><span class="line">cd /data/mapreduce2</span><br><span class="line"><span class="meta">#</span><span class="bash">下载并解压压缩包，点击文章开头的百度云链接获取全部数据以及依赖包</span></span><br><span class="line">gunzip buyer_favotite1.bz</span><br><span class="line">tar xzvf hadoop2lib.tar.gz</span><br></pre></td></tr></table></figure>

<p><a href="https://pan.baidu.com/s/1caYKVt-BKGSpAZGD5iPVMw" target="_blank" rel="noopener">去重实例数据包——buyer_favorite1</a></p>
<p>提取码：9t51</p>
<p>3.在HDFS上创建/in目录，并移动数据文件至in目录中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /mymapreduce2/in</span><br><span class="line">hadoop fs -put /data/mapreduce2/buyer_favorite1 /mymapreduce2/in</span><br></pre></td></tr></table></figure>

<p>4.创建java项目，并编写程序且执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">setp1:新建Java Project项目，项目名为mapreduce2</span><br><span class="line">step2:在mapreduce2项目下新建包，包名为mapreduce</span><br><span class="line">step3:在mapreduce包下新建类，类名为Filter</span><br><span class="line">step4:添加项目所需依赖的jar包右键项目，新建一个文件夹，命名为：hadoop2lib,用于存放项目所需的jar包</span><br><span class="line">step5:将&#x2F;data&#x2F;mapreduce2目录下，hadoop2lib目录中的jar包，拷贝到eclipse中mapreduce2项目的hadoop2lib目录下</span><br><span class="line">step6:选中所有项目hadoop2lib目录下所有jar包，并添加到Build Path中</span><br><span class="line">step:7在Filter类文件中，右键并点击&#x3D;&gt;Run As&#x3D;&gt;Run on Hadoop选项，将MapReduce任务提交到Hadoop中</span><br></pre></td></tr></table></figure>

<p>项目文件层级关系如下：</p>
<p><img src="F:%5CMy_Study%5CBlog_Shaw%5CmyBlog%5Csource_posts%5CBigData%5CHadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0%5C2.1.PNG" alt=""></p>
<p><img src="F:%5CMy_Study%5CBlog_Shaw%5CmyBlog%5Csource_posts%5CBigData%5CHadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0%5C2.2.PNG" alt=""></p>
<p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Map代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span> , <span class="title">Text</span> , <span class="title">Text</span> , <span class="title">NullWritable</span>&gt;  </span></span><br><span class="line"><span class="class">    //<span class="title">map</span>将输入中的<span class="title">value</span>复制到输出数据的<span class="title">key</span>上，并直接输出  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Text newKey=<span class="keyword">new</span> Text();      <span class="comment">//从输入中得到的每行的数据的类型  </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException  </span></span><br><span class="line"><span class="function">    <span class="comment">//实现map函数  </span></span></span><br><span class="line"><span class="function">    </span>&#123;             <span class="comment">//获取并输出每一次的处理过程  </span></span><br><span class="line">    String line=value.toString();  </span><br><span class="line">	System.out.println(line);  </span><br><span class="line">    String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">    newKey.set(arr[<span class="number">1</span>]);  </span><br><span class="line">    context.write(newKey, NullWritable.get());  </span><br><span class="line">    System.out.println(newKey);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="comment">//map阶段采用Hadoop的默认的作业输入方式，把输入的value用split()方法截取，截取出的商品id字段设置为key,设置value为空，然后直接输出&lt;key,value&gt;。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//reduce端代码</span></span><br><span class="line"></span><br><span class="line">view plain copy</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">NullWritable</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;NullWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException  </span></span><br><span class="line"><span class="function">    <span class="comment">//实现reduce函数  </span></span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    context.write(key,NullWritable.get());   <span class="comment">//获取并输出每一次的处理过程  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="comment">//map输出的&lt;key,value&gt;键值对经过shuffle过程，聚成&lt;key,value-list&gt;后，会交给reduce函数。reduce函数,不管每个key 有多少个value，它直接将输入的值赋值给输出的key，将输出的value设置为空，然后输出&lt;key,value&gt;就可以了。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//完整代码</span></span><br><span class="line"></span><br><span class="line">view plain copy</span><br><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Filter</span></span>&#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span> , <span class="title">Text</span> , <span class="title">Text</span> , <span class="title">NullWritable</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Text newKey=<span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    String line=value.toString();  </span><br><span class="line">    System.out.println(line);  </span><br><span class="line">    String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">    newKey.set(arr[<span class="number">1</span>]);  </span><br><span class="line">    context.write(newKey, NullWritable.get());  </span><br><span class="line">    System.out.println(newKey);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">NullWritable</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;NullWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">        context.write(key,NullWritable.get());  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException</span>&#123;  </span><br><span class="line">        Configuration conf=<span class="keyword">new</span> Configuration();  </span><br><span class="line">        System.out.println(<span class="string">"start"</span>);  </span><br><span class="line">        Job job =<span class="keyword">new</span> Job(conf,<span class="string">"filter"</span>);  </span><br><span class="line">        job.setJarByClass(Filter<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputValueClass(NullWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        Path in=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce2/in/buyer_favorite1"</span>);  </span><br><span class="line">        Path out=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce2/out"</span>);  </span><br><span class="line">        FileInputFormat.addInputPath(job,in);  </span><br><span class="line">        FileOutputFormat.setOutputPath(job,out);  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<p>5.查看实验结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /mymapreduce2/out  </span><br><span class="line">hadoop fs -cat /mymapreduce2/out/part-r-00000</span><br></pre></td></tr></table></figure>

<h5 id="MapReduce实例——排序"><a href="#MapReduce实例——排序" class="headerlink" title="MapReduce实例——排序"></a>MapReduce实例——排序</h5><h6 id="任务目标-2"><a href="#任务目标-2" class="headerlink" title="任务目标"></a>任务目标</h6><p>1.准确理解Mapreduce排序的实验原理</p>
<p>2.熟练掌握Mapreduce排序的程序代码编写</p>
<p>3.培养编写MapReduce排序代码解决问题的能力</p>
<h6 id="相关知识-2"><a href="#相关知识-2" class="headerlink" title="相关知识"></a>相关知识</h6><p>Map、Reduce任务中Shuffle和排序的过程图如下：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e30f996-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e30f996-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<p>流程分析：</p>
<p>1.Map端：</p>
<p>（1）每个输入分片会让一个map任务来处理，默认情况下，以HDFS的一个块的大小（默认为64M）为一个分片，当然我们也可以设置块的大小。map输出的结果会暂且放在一个环形内存缓冲区中（该缓冲区的大小默认为100M，由io.sort.mb属性控制），当该缓冲区快要溢出时（默认为缓冲区大小的80%，由io.sort.spill.percent属性控制），会在本地文件系统中创建一个溢出文件，将该缓冲区中的数据写入这个文件。</p>
<p>（2）在写入磁盘之前，线程首先根据reduce任务的数目将数据划分为相同数目的分区，也就是一个reduce任务对应一个分区的数据。这样做是为了避免有些reduce任务分配到大量数据，而有些reduce任务却分到很少数据，甚至没有分到数据的尴尬局面。其实分区就是对数据进行hash的过程。然后对每个分区中的数据进行排序，如果此时设置了Combiner，将排序后的结果进行Combia操作，这样做的目的是让尽可能少的数据写入到磁盘。</p>
<p>（3）当map任务输出最后一个记录时，可能会有很多的溢出文件，这时需要将这些文件合并。合并的过程中会不断地进行排序和combia操作，目的有两个：①尽量减少每次写入磁盘的数据量。②尽量减少下一复制阶段网络传输的数据量。最后合并成了一个已分区且已排序的文件。为了减少网络传输的数据量，这里可以将数据压缩，只要将mapred.compress.map.out设置为true就可以了。</p>
<p>（4）将分区中的数据拷贝给相对应的reduce任务。有人可能会问：分区中的数据怎么知道它对应的reduce是哪个呢？其实map任务一直和其父TaskTracker保持联系，而TaskTracker又一直和JobTracker保持心跳。所以JobTracker中保存了整个集群中的宏观信息。只要reduce任务向JobTracker获取对应的map输出位置就ok了哦。</p>
<p>到这里，map端就分析完了。那到底什么是Shuffle呢？Shuffle的中文意思是“洗牌”，如果我们这样看：一个map产生的数据，结果通过hash过程分区却分配给了不同的reduce任务，是不是一个对数据洗牌的过程呢？</p>
<p>2.Reduce端：</p>
<p>（1）Reduce会接收到不同map任务传来的数据，并且每个map传来的数据都是有序的。如果reduce端接受的数据量相当小，则直接存储在内存中（缓冲区大小由mapred.job.shuffle.input.buffer.percent属性控制，表示用作此用途的堆空间的百分比），如果数据量超过了该缓冲区大小的一定比例（由mapred.job.shuffle.merge.percent决定），则对数据合并后溢写到磁盘中。</p>
<p>（2）随着溢写文件的增多，后台线程会将它们合并成一个更大的有序的文件，这样做是为了给后面的合并节省时间。其实不管在map端还是reduce端，MapReduce都是反复地执行排序，合并操作，现在终于明白了有些人为什么会说：排序是hadoop的灵魂。</p>
<p>（3）合并的过程中会产生许多的中间文件（写入磁盘了），但MapReduce会让写入磁盘的数据尽可能地少，并且最后一次合并的结果并没有写入磁盘，而是直接输入到reduce函数。</p>
<p>熟悉MapReduce的人都知道：排序是MapReduce的天然特性！在数据达到reducer之前，MapReduce框架已经对这些数据按键排序了。但是在使用之前，首先需要了解它的默认排序规则。它是按照key值进行排序的，如果key为封装的int为IntWritable类型，那么MapReduce按照数字大小对key排序，如果Key为封装String的Text类型，那么MapReduce将按照数据字典顺序对字符排序。</p>
<p>了解了这个细节，我们就知道应该使用封装int的Intwritable型数据结构了，也就是在map这里，将读入的数据中要排序的字段转化为Intwritable型，然后作为key值输出（不排序的字段作为value）。reduce阶段拿到&lt;key，value-list&gt;之后，将输入的key作为输出的key，并根据value-list中的元素的个数决定输出的次数。</p>
<h6 id="任务内容-1"><a href="#任务内容-1" class="headerlink" title="任务内容"></a>任务内容</h6><p>在电商网站上，当我们进入某电商页面里浏览商品时，就会产生用户对商品访问情况的数据 ，名为goods_visit1，goods_visit1中包含（商品id ，点击次数）两个字段，内容以“\t”分割，由于数据量很大，所以为了方便统计我们只截取它的一部分数据，内容如下：</p>
<table>
<thead>
<tr>
<th>商品id</th>
<th>点击次数</th>
</tr>
</thead>
<tbody><tr>
<td>1010037</td>
<td>100</td>
</tr>
<tr>
<td>1010102</td>
<td>100</td>
</tr>
<tr>
<td>1010152</td>
<td>97</td>
</tr>
<tr>
<td>1010178</td>
<td>96</td>
</tr>
<tr>
<td>1010320</td>
<td>103</td>
</tr>
<tr>
<td>1010510</td>
<td>104</td>
</tr>
</tbody></table>
<p>要求我们编写mapreduce程序来对商品点击次数有低到高进行排序。</p>
<p>实验结果数据如下：</p>
<table>
<thead>
<tr>
<th>商品id</th>
<th>点击次数</th>
</tr>
</thead>
<tbody><tr>
<td>1010178</td>
<td>96</td>
</tr>
<tr>
<td>1010152</td>
<td>97</td>
</tr>
<tr>
<td>1010037</td>
<td>100</td>
</tr>
<tr>
<td>1010102</td>
<td>100</td>
</tr>
<tr>
<td>1010320</td>
<td>103</td>
</tr>
<tr>
<td>1010510</td>
<td>104</td>
</tr>
</tbody></table>
<h6 id="任务步骤-2"><a href="#任务步骤-2" class="headerlink" title="任务步骤"></a>任务步骤</h6><p>1.启动Hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">切换到hadoop的sbin目录下</span></span><br><span class="line">cd /apps/hadoop/sbin</span><br><span class="line"><span class="meta">#</span><span class="bash">启动Hadoop</span></span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>

<p>2.新建目录，下载数据包并下载和解压依赖包hadoop2lib.tar.gz</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">新建目录是为了方便进行项目数据的整理</span></span><br><span class="line">mkdir -p /data/mapreduce3</span><br><span class="line">cd /data/mapreduce3</span><br><span class="line"><span class="meta">#</span><span class="bash">下载并解压压缩包，点击文章开头的百度云链接获取全部数据以及依赖包</span></span><br><span class="line">gunzip goods_visit1.gz</span><br><span class="line">tar xzvf hadoop2lib.tar.gz</span><br></pre></td></tr></table></figure>

<p>3.在HDFS上创建/in目录，并移动数据文件至in目录中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /mymapreduce3/in</span><br><span class="line">hadoop fs -put /data/mapreduce3/goods_visit1 /mymapreduce3/in</span><br></pre></td></tr></table></figure>

<p>4.创建java项目，并编写程序且执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">setp1:新建Java Project项目，项目名为mapreduce3</span><br><span class="line">step2:在mapreduce3项目下新建包，包名为mapreduce</span><br><span class="line">step3:在mapreduce包下新建类，类名为OneSort</span><br><span class="line">step4:添加项目所需依赖的jar包右键项目，新建一个文件夹，命名为：hadoop2lib,用于存放项目所需的jar包</span><br><span class="line">step5:将&#x2F;data&#x2F;mapreduce3目录下，hadoop2lib目录中的jar包，拷贝到eclipse中mapreduce3项目的hadoop2lib目录下</span><br><span class="line">step6:选中所有项目hadoop2lib目录下所有jar包，并添加到Build Path中</span><br><span class="line">step:7在OneSort类文件中，右键并点击&#x3D;&gt;Run As&#x3D;&gt;Run on Hadoop选项，将MapReduce任务提交到Hadoop中</span><br></pre></td></tr></table></figure>

<p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Java代码，并描述其设计思路</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//在MapReduce过程中默认就有对数据的排序。它是按照key值进行排序的，如果key为封装int的IntWritable类型，那么MapReduce会按照数字大小对key排序，如果Key为封装String的Text类型，那么MapReduce将按照数据字典顺序对字符排序。在本例中我们用到第一种，key设置为IntWritable类型，其中MapReduce程序主要分为Map部分和Reduce部分。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Map部分代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> Text goods=<span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> IntWritable num=<span class="keyword">new</span> IntWritable();  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">            String line=value.toString();  </span><br><span class="line">            String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">            num.set(Integer.parseInt(arr[<span class="number">1</span>]));  </span><br><span class="line">            goods.set(arr[<span class="number">0</span>]);  </span><br><span class="line">            context.write(num,goods);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="comment">//在map端采用Hadoop默认的输入方式之后，将输入的value值用split()方法截取，把要排序的点击次数字段转化为IntWritable类型并设置为key，商品id字段设置为value，然后直接输出&lt;key,value&gt;。map输出的&lt;key,value&gt;先要经过shuffle过程把相同key值的所有value聚集起来形成&lt;key,value-list&gt;后交给reduce端。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Reduce部分代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> IntWritable result= <span class="keyword">new</span> IntWritable();  </span><br><span class="line">                 <span class="comment">//声明对象result  </span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntWritable key,Iterable&lt;Text&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    <span class="keyword">for</span>(Text val:values)&#123;  </span><br><span class="line">    context.write(key,val);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="comment">//完整代码</span></span><br><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OneSort</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span> , <span class="title">Text</span> , <span class="title">IntWritable</span>,<span class="title">Text</span> &gt;</span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Text goods=<span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> IntWritable num=<span class="keyword">new</span> IntWritable();  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    String line=value.toString();  </span><br><span class="line">    String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">    num.set(Integer.parseInt(arr[<span class="number">1</span>]));  </span><br><span class="line">    goods.set(arr[<span class="number">0</span>]);  </span><br><span class="line">    context.write(num,goods);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt; <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> IntWritable result= <span class="keyword">new</span> IntWritable();  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntWritable key,Iterable&lt;Text&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">        <span class="keyword">for</span>(Text val:values)&#123;  </span><br><span class="line">        context.write(key,val);  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException</span>&#123;  </span><br><span class="line">        Configuration conf=<span class="keyword">new</span> Configuration();  </span><br><span class="line">        Job job =<span class="keyword">new</span> Job(conf,<span class="string">"OneSort"</span>);  </span><br><span class="line">        job.setJarByClass(OneSort<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputKeyClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        Path in=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce3/in/goods_visit1"</span>);  </span><br><span class="line">        Path out=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce3/out"</span>);  </span><br><span class="line">        FileInputFormat.addInputPath(job,in);  </span><br><span class="line">        FileOutputFormat.setOutputPath(job,out);  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<p>5.查看实验结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /mymapreduce3/out  </span><br><span class="line">hadoop fs -cat /mymapreduce3/out/part-r-00000</span><br></pre></td></tr></table></figure>

<p><em>之后实例的步骤与前三个步骤一致，不同的便是代码，此后就直接码上代码，省略详细步骤了</em></p>
<h5 id="MapReduce实例——求平均值"><a href="#MapReduce实例——求平均值" class="headerlink" title="MapReduce实例——求平均值"></a>MapReduce实例——求平均值</h5><h6 id="相关知识-3"><a href="#相关知识-3" class="headerlink" title="相关知识"></a>相关知识</h6><p>求平均数是MapReduce比较常见的算法，求平均数的算法也比较简单，一种思路是Map端读取数据，在数据输入到Reduce之前先经过shuffle，将map函数输出的key值相同的所有的value值形成一个集合value-list，然后将输入到Reduce端，Reduce端汇总并且统计记录数，然后作商即可。具体原理如下图所示：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e3fa46d-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e3fa46d-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<h6 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Mapper代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span> , <span class="title">Text</span> , <span class="title">Text</span> , <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Text newKey=<span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="comment">//实现map函数  </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    <span class="comment">// 将输入的纯文本文件的数据转化成String  </span></span><br><span class="line">    String line=value.toString();  </span><br><span class="line">    System.out.println(line);  </span><br><span class="line">    String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">    newKey.set(arr[<span class="number">0</span>]);  </span><br><span class="line">    <span class="keyword">int</span> click=Integer.parseInt(arr[<span class="number">1</span>]);  </span><br><span class="line">    context.write(newKey, <span class="keyword">new</span> IntWritable(click));  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="comment">//map端在采用Hadoop的默认输入方式之后，将输入的value值通过split()方法截取出来，我们把截取的商品点击次数字段转化为IntWritable类型并将其设置为value，把商品分类字段设置为key,然后直接输出key/value的值。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Reducer代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line"><span class="comment">//实现reduce函数  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> num=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">int</span> count=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">for</span>(IntWritable val:values)&#123;  </span><br><span class="line">    num+=val.get(); <span class="comment">//每个元素求和num  </span></span><br><span class="line">    count++;        <span class="comment">//统计元素的次数count  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">int</span> avg=num/count;  <span class="comment">//计算平均数  </span></span><br><span class="line">  </span><br><span class="line">    context.write(key,<span class="keyword">new</span> IntWritable(avg));  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyAverage</span></span>&#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span> , <span class="title">Text</span> , <span class="title">Text</span> , <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Text newKey=<span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">    String line=value.toString();  </span><br><span class="line">    System.out.println(line);  </span><br><span class="line">    String arr[]=line.split(<span class="string">"\t"</span>);  </span><br><span class="line">    newKey.set(arr[<span class="number">0</span>]);  </span><br><span class="line">    <span class="keyword">int</span> click=Integer.parseInt(arr[<span class="number">1</span>]);  </span><br><span class="line">    context.write(newKey, <span class="keyword">new</span> IntWritable(click));  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;  </span><br><span class="line">        <span class="keyword">int</span> num=<span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">int</span> count=<span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">for</span>(IntWritable val:values)&#123;  </span><br><span class="line">        num+=val.get();  </span><br><span class="line">        count++;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="keyword">int</span> avg=num/count;  </span><br><span class="line">        context.write(key,<span class="keyword">new</span> IntWritable(avg));  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException</span>&#123;  </span><br><span class="line">        Configuration conf=<span class="keyword">new</span> Configuration();  </span><br><span class="line">        System.out.println(<span class="string">"start"</span>);  </span><br><span class="line">        Job job =<span class="keyword">new</span> Job(conf,<span class="string">"MyAverage"</span>);  </span><br><span class="line">        job.setJarByClass(MyAverage<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        Path in=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce4/in/goods_click"</span>);  </span><br><span class="line">        Path out=<span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce4/out"</span>);  </span><br><span class="line">        FileInputFormat.addInputPath(job,in);  </span><br><span class="line">        FileOutputFormat.setOutputPath(job,out);  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——Reduce端join"><a href="#MapReduce实例——Reduce端join" class="headerlink" title="MapReduce实例——Reduce端join"></a>MapReduce实例——Reduce端join</h5><h6 id="相关知识-4"><a href="#相关知识-4" class="headerlink" title="相关知识"></a>相关知识</h6><p>在Reudce端进行Join连接是MapReduce框架进行表之间Join操作最为常见的模式。</p>
<p>1.Reduce端Join实现原理</p>
<p>（1）Map端的主要工作，为来自不同表（文件）的key/value对打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</p>
<p>（2）Reduce端的主要工作，在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录（在map阶段已经打标志）分开，最后进行笛卡尔只就ok了。</p>
<p>2.Reduce端Join的使用场景</p>
<p>Reduce端连接比Map端连接更为普遍，因为在map阶段不能获取所有需要的join字段，即：同一个key对应的字段可能位于不同map中，但是Reduce端连接效率比较低，因为所有数据都必须经过Shuffle过程。</p>
<p>3.本实验的Reduce端Join代码执行流程：</p>
<p>（1）Map端读取所有的文件，并在输出的内容里加上标识，代表数据是从哪个文件里来的。</p>
<p>（2）在Reduce处理函数中，按照标识对数据进行处理。</p>
<p>（3）然后将相同的key值进行Join连接操作，求出结果并直接输出。</p>
<h6 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1)Map端读取所有的文件，并在输出的内容里加上标识，代表数据是从哪个文件里来的。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//(2)在reduce处理函数中，按照标识对数据进行处理。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//(3)然后将相同key值进行join连接操作，求出结果并直接输出。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;  </span><br><span class="line"><span class="keyword">import</span> java.util.Vector;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReduceJoin</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">mymapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span>  </span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">            String filePath = ((FileSplit)context.getInputSplit()).getPath().toString();  </span><br><span class="line">            <span class="keyword">if</span> (filePath.contains(<span class="string">"orders1"</span>)) &#123;  </span><br><span class="line">                String line = value.toString();  </span><br><span class="line">                String[] arr = line.split(<span class="string">"\t"</span>);  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(arr[<span class="number">0</span>]), <span class="keyword">new</span> Text( <span class="string">"1+"</span> + arr[<span class="number">2</span>]+<span class="string">"\t"</span>+arr[<span class="number">3</span>]));  </span><br><span class="line">                <span class="comment">//System.out.println(arr[0] + "_1+" + arr[2]+"\t"+arr[3]);  </span></span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(filePath.contains(<span class="string">"order_items1"</span>)) &#123;  </span><br><span class="line">                String line = value.toString();  </span><br><span class="line">                String[] arr = line.split(<span class="string">"\t"</span>);  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(arr[<span class="number">1</span>]), <span class="keyword">new</span> Text(<span class="string">"2+"</span> + arr[<span class="number">2</span>]));  </span><br><span class="line">                <span class="comment">//System.out.println(arr[1] + "_2+" + arr[2]);  </span></span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myreducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">    Vector&lt;String&gt; left  = <span class="keyword">new</span> Vector&lt;String&gt;();  </span><br><span class="line">        Vector&lt;String&gt; right = <span class="keyword">new</span> Vector&lt;String&gt;();  </span><br><span class="line">            <span class="keyword">for</span> (Text val : values) &#123;  </span><br><span class="line">            String str = val.toString();  </span><br><span class="line">            <span class="keyword">if</span> (str.startsWith(<span class="string">"1+"</span>)) &#123;  </span><br><span class="line">            left.add(str.substring(<span class="number">2</span>));  </span><br><span class="line">            &#125;  </span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (str.startsWith(<span class="string">"2+"</span>)) &#123;  </span><br><span class="line">            right.add(str.substring(<span class="number">2</span>));  </span><br><span class="line">            &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">int</span> sizeL = left.size();  </span><br><span class="line">            <span class="keyword">int</span> sizeR = right.size();  </span><br><span class="line">            <span class="comment">//System.out.println(key + "left:"+left);  </span></span><br><span class="line">            <span class="comment">//System.out.println(key + "right:"+right);  </span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sizeL; i++) &#123;  </span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; sizeR; j++) &#123;  </span><br><span class="line">            context.write( key, <span class="keyword">new</span> Text(  left.get(i) + <span class="string">"\t"</span> + right.get(j) ) );  </span><br><span class="line">            <span class="comment">//System.out.println(key + " \t" + left.get(i) + "\t" + right.get(j));  </span></span><br><span class="line">            &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;  </span><br><span class="line">            Job job = Job.getInstance();  </span><br><span class="line">            job.setJobName(<span class="string">"reducejoin"</span>);  </span><br><span class="line">            job.setJarByClass(ReduceJoin<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">            job.setMapperClass(mymapper<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setReducerClass(myreducer<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">            job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">            Path left = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce6/in/orders1"</span>);  </span><br><span class="line">            Path right = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce6/in/order_items1"</span>);  </span><br><span class="line">            Path out = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce6/out"</span>);  </span><br><span class="line">  </span><br><span class="line">            FileInputFormat.addInputPath(job, left);  </span><br><span class="line">            FileInputFormat.addInputPath(job, right);  </span><br><span class="line">            FileOutputFormat.setOutputPath(job, out);  </span><br><span class="line">  </span><br><span class="line">            System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">            &#125;  </span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——Map端join"><a href="#MapReduce实例——Map端join" class="headerlink" title="MapReduce实例——Map端join"></a>MapReduce实例——Map端join</h5><h6 id="相关知识-5"><a href="#相关知识-5" class="headerlink" title="相关知识"></a>相关知识</h6><p>MapReduce提供了表连接操作其中包括Map端join、Reduce端join还有单表连接，现在我们要讨论的是Map端join，Map端join是指数据到达map处理函数之前进行合并的，效率要远远高于Reduce端join，因为Reduce端join是把所有的数据都经过Shuffle，非常消耗资源。</p>
<p>1.Map端join的使用场景：一张表数据十分小、一张表数据很大。</p>
<p>Map端join是针对以上场景进行的优化：将小表中的数据全部加载到内存，按关键字建立索引。大表中的数据作为map的输入，对map()函数每一对&lt;key,value&gt;输入，都能够方便地和已加载到内存的小数据进行连接。把连接结果按key输出，经过shuffle阶段，reduce端得到的就是已经按key分组并且连接好了的数据。</p>
<p>为了支持文件的复制，Hadoop提供了一个类DistributedCache，使用该类的方法如下：</p>
<p>（1）用户使用静态方法DistributedCache.addCacheFile()指定要复制的文件，它的参数是文件的URI（如果是HDFS上的文件，可以这样：hdfs://namenode:9000/home/XXX/file，其中9000是自己配置的NameNode端口号）。JobTracker在作业启动之前会获取这个URI列表，并将相应的文件拷贝到各个TaskTracker的本地磁盘上。</p>
<p>（2）用户使用DistributedCache.getLocalCacheFiles()方法获取文件目录，并使用标准的文件读写API读取相应的文件。</p>
<p>2.本实验Map端Join的执行流程</p>
<p>（1）首先在提交作业的时候先将小表文件放到该作业的DistributedCache中，然后从DistributeCache中取出该小表进行join连接的 &lt;key ,value&gt;键值对，将其解释分割放到内存中（可以放大Hash Map等等容器中）。</p>
<p>（2）要重写MyMapper类下面的setup()方法，因为这个方法是先于map方法执行的，将较小表先读入到一个HashMap中。</p>
<p>（3）重写map函数，一行行读入大表的内容，逐一的与HashMap中的内容进行比较，若Key相同，则对数据进行格式化处理，然后直接输出。</p>
<p>（4）map函数输出的&lt;key,value &gt;键值对首先经过一个suffle把key值相同的所有value放到一个迭代器中形成values，然后将&lt;key,values&gt;键值对传递给reduce函数，reduce函数输入的key直接复制给输出的key，输入的values通过增强版for循环遍历逐一输出，循环的次数决定了&lt;key,value&gt;输出的次数。</p>
<h6 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;  </span><br><span class="line"><span class="keyword">import</span> java.io.FileReader;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.net.URI;  </span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;  </span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;  </span><br><span class="line"><span class="keyword">import</span> java.util.Map;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoin</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> Map&lt;String, String&gt; dict = <span class="keyword">new</span> HashMap&lt;&gt;();  </span><br><span class="line">  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,  </span></span><br><span class="line"><span class="function">                InterruptedException </span>&#123;  </span><br><span class="line">            String fileName = context.getLocalCacheFiles()[<span class="number">0</span>].getName();  </span><br><span class="line">            <span class="comment">//System.out.println(fileName);  </span></span><br><span class="line">            BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(fileName));  </span><br><span class="line">            String codeandname = <span class="keyword">null</span>;  </span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">null</span> != ( codeandname = reader.readLine() ) ) &#123;  </span><br><span class="line">                String str[]=codeandname.split(<span class="string">"\t"</span>);  </span><br><span class="line">                dict.put(str[<span class="number">0</span>], str[<span class="number">2</span>]+<span class="string">"\t"</span>+str[<span class="number">3</span>]);  </span><br><span class="line">            &#125;  </span><br><span class="line">            reader.close();  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span>  </span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">            String[] kv = value.toString().split(<span class="string">"\t"</span>);  </span><br><span class="line">            <span class="keyword">if</span> (dict.containsKey(kv[<span class="number">1</span>])) &#123;  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(kv[<span class="number">1</span>]), <span class="keyword">new</span> Text(dict.get(kv[<span class="number">1</span>])+<span class="string">"\t"</span>+kv[<span class="number">2</span>]));  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">for</span> (Text text : values) &#123;  </span><br><span class="line">    context.write(key, text);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ClassNotFoundException, IOException, InterruptedException, URISyntaxException </span>&#123;  </span><br><span class="line">    Job job = Job.getInstance();  </span><br><span class="line">    job.setJobName(<span class="string">"mapjoin"</span>);  </span><br><span class="line">    job.setJarByClass(MapJoin<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setMapperClass(MyMapper<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setReducerClass(MyReducer<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    Path in = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce5/in/order_items1"</span>);  </span><br><span class="line">    Path out = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce5/out"</span>);  </span><br><span class="line">    FileInputFormat.addInputPath(job, in);  </span><br><span class="line">    FileOutputFormat.setOutputPath(job, out);  </span><br><span class="line">  </span><br><span class="line">    URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://localhost:9000/mymapreduce5/in/orders1"</span>);  </span><br><span class="line">    job.addCacheFile(uri);  </span><br><span class="line">  </span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——单表Join"><a href="#MapReduce实例——单表Join" class="headerlink" title="MapReduce实例——单表Join"></a>MapReduce实例——单表Join</h5><h6 id="相关知识-6"><a href="#相关知识-6" class="headerlink" title="相关知识"></a>相关知识</h6><p>以本实验的buyer1(buyer_id,friends_id)表为例来阐述单表连接的实验原理。单表连接，连接的是左表的buyer_id列和右表的friends_id列，且左表和右表是同一个表。因此，在map阶段将读入数据分割成buyer_id和friends_id之后，会将buyer_id设置成key，friends_id设置成value，直接输出并将其作为左表；再将同一对buyer_id和friends_id中的friends_id设置成key，buyer_id设置成value进行输出，作为右表。为了区分输出中的左右表，需要在输出的value中再加上左右表的信息，比如在value的String最开始处加上字符1表示左表，加上字符2表示右表。这样在map的结果中就形成了左表和右表，然后在shuffle过程中完成连接。reduce接收到连接的结果，其中每个key的value-list就包含了”buyer_idfriends_id–friends_idbuyer_id”关系。取出每个key的value-list进行解析，将左表中的buyer_id放入一个数组，右表中的friends_id放入一个数组，然后对两个数组求笛卡尔积就是最后的结果了。</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e693f7d-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e693f7d-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<h6 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DanJoin</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>,<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span>  </span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException,InterruptedException</span>&#123;  </span><br><span class="line">                String line = value.toString();  </span><br><span class="line">                String[] arr = line.split(<span class="string">"\t"</span>);  </span><br><span class="line">                String mapkey=arr[<span class="number">0</span>];  </span><br><span class="line">                String mapvalue=arr[<span class="number">1</span>];  </span><br><span class="line">                String relationtype=<span class="keyword">new</span> String();  </span><br><span class="line">                relationtype=<span class="string">"1"</span>;  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(mapkey),<span class="keyword">new</span> Text(relationtype+<span class="string">"+"</span>+mapvalue));  </span><br><span class="line">                <span class="comment">//System.out.println(relationtype+"+"+mapvalue);  </span></span><br><span class="line">                relationtype=<span class="string">"2"</span>;  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(mapvalue),<span class="keyword">new</span> Text(relationtype+<span class="string">"+"</span>+mapkey));  </span><br><span class="line">                <span class="comment">//System.out.println(relationtype+"+"+mapvalue);  </span></span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;Text&gt; values,Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException,InterruptedException</span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> buyernum=<span class="number">0</span>;  </span><br><span class="line">    String[] buyer=<span class="keyword">new</span> String[<span class="number">20</span>];  </span><br><span class="line">    <span class="keyword">int</span> friendsnum=<span class="number">0</span>;  </span><br><span class="line">    String[] friends=<span class="keyword">new</span> String[<span class="number">20</span>];  </span><br><span class="line">    Iterator ite=values.iterator();  </span><br><span class="line">    <span class="keyword">while</span>(ite.hasNext())&#123;  </span><br><span class="line">    String record=ite.next().toString();  </span><br><span class="line">    <span class="keyword">int</span> len=record.length();  </span><br><span class="line">    <span class="keyword">int</span> i=<span class="number">2</span>;  </span><br><span class="line">    <span class="keyword">if</span>(<span class="number">0</span>==len)&#123;  </span><br><span class="line">    <span class="keyword">continue</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">char</span> relationtype=record.charAt(<span class="number">0</span>);  </span><br><span class="line">    <span class="keyword">if</span>(<span class="string">'1'</span>==relationtype)&#123;  </span><br><span class="line">    buyer [buyernum]=record.substring(i);  </span><br><span class="line">    buyernum++;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">if</span>(<span class="string">'2'</span>==relationtype)&#123;  </span><br><span class="line">    friends[friendsnum]=record.substring(i);  </span><br><span class="line">    friendsnum++;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">if</span>(<span class="number">0</span>!=buyernum&amp;&amp;<span class="number">0</span>!=friendsnum)&#123;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> m=<span class="number">0</span>;m&lt;buyernum;m++)&#123;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> n=<span class="number">0</span>;n&lt;friendsnum;n++)&#123;  </span><br><span class="line">    <span class="keyword">if</span>(buyer[m]!=friends[n])&#123;  </span><br><span class="line">    context.write(<span class="keyword">new</span> Text(buyer[m]),<span class="keyword">new</span> Text(friends[n]));  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;  </span><br><span class="line">  </span><br><span class="line">    Configuration conf=<span class="keyword">new</span> Configuration();  </span><br><span class="line">    String[] otherArgs=<span class="keyword">new</span> String[<span class="number">2</span>];  </span><br><span class="line">    otherArgs[<span class="number">0</span>]=<span class="string">"hdfs://localhost:9000/mymapreduce7/in/buyer1"</span>;  </span><br><span class="line">    otherArgs[<span class="number">1</span>]=<span class="string">"hdfs://localhost:9000/mymapreduce7/out"</span>;  </span><br><span class="line">    Job job=<span class="keyword">new</span> Job(conf,<span class="string">" Table join"</span>);  </span><br><span class="line">    job.setJarByClass(DanJoin<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));  </span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));  </span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>)?<span class="number">0</span>:<span class="number">1</span>);  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——二次排序"><a href="#MapReduce实例——二次排序" class="headerlink" title="MapReduce实例——二次排序"></a>MapReduce实例——二次排序</h5><h6 id="相关知识-7"><a href="#相关知识-7" class="headerlink" title="相关知识"></a>相关知识</h6><p>在Map阶段，使用job.setInputFormatClass定义的InputFormat将输入的数据集分割成小数据块splites，同时InputFormat提供一个RecordReder的实现。本实验中使用的是TextInputFormat，他提供的RecordReder会将文本的字节偏移量作为key，这一行的文本作为value。这就是自定义Map的输入是&lt;LongWritable, Text&gt;的原因。然后调用自定义Map的map方法，将一个个&lt;LongWritable, Text&gt;键值对输入给Map的map方法。注意输出应该符合自定义Map中定义的输出&lt;IntPair, IntWritable&gt;。最终是生成一个List&lt;IntPair, IntWritable&gt;。在map阶段的最后，会先调用job.setPartitionerClass对这个List进行分区，每个分区映射到一个reducer。每个分区内又调用job.setSortComparatorClass设置的key比较函数类排序。可以看到，这本身就是一个二次排序。 如果没有通过job.setSortComparatorClass设置key比较函数类，则可以使用key实现的compareTo方法进行排序。 在本实验中，就使用了IntPair实现的compareTo方法。</p>
<p>在Reduce阶段，reducer接收到所有映射到这个reducer的map输出后，也是会调用job.setSortComparatorClass设置的key比较函数类对所有数据对排序。然后开始构造一个key对应的value迭代器。这时就要用到分组，使用job.setGroupingComparatorClass设置的分组函数类。只要这个比较器比较的两个key相同，他们就属于同一个组，它们的value放在一个value迭代器，而这个迭代器的key使用属于同一个组的所有key的第一个key。最后就是进入Reducer的reduce方法，reduce方法的输入是所有的（key和它的value迭代器）。同样注意输入与输出的类型必须与自定义的Reducer中声明的一致。</p>
<h6 id="code"><a href="#code" class="headerlink" title="code"></a>code</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;  </span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondarySort</span>  </span></span><br><span class="line"><span class="class"></span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntPair</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">IntPair</span>&gt;  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> first;  </span><br><span class="line">    <span class="keyword">int</span> second;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    first = left;  </span><br><span class="line">    second = right;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getFirst</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> first;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSecond</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> second;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="comment">// TODO Auto-generated method stub  </span></span><br><span class="line">    first = in.readInt();  </span><br><span class="line">    second = in.readInt();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="comment">// TODO Auto-generated method stub  </span></span><br><span class="line">    out.writeInt(first);  </span><br><span class="line">    out.writeInt(second);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(IntPair o)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="comment">// TODO Auto-generated method stub  </span></span><br><span class="line">    <span class="keyword">if</span> (first != o.first)  </span><br><span class="line">    &#123;  </span><br><span class="line">    <span class="keyword">return</span> first &lt; o.first ? <span class="number">1</span> : -<span class="number">1</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (second != o.second)  </span><br><span class="line">    &#123;  </span><br><span class="line">    <span class="keyword">return</span> second &lt; o.second ? -<span class="number">1</span> : <span class="number">1</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> first * <span class="number">157</span> + second;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object right)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (right == <span class="keyword">null</span>)  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;  </span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span> == right)  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;  </span><br><span class="line">    <span class="keyword">if</span> (right <span class="keyword">instanceof</span> IntPair)  </span><br><span class="line">    &#123;  </span><br><span class="line">    IntPair r = (IntPair) right;  </span><br><span class="line">    <span class="keyword">return</span> r.first == first &amp;&amp; r.second == second;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FirstPartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">IntPair</span>, <span class="title">IntWritable</span>&gt;  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(IntPair key, IntWritable value,<span class="keyword">int</span> numPartitions)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> Math.abs(key.getFirst() * <span class="number">127</span>) % numPartitions;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupingComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span>  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">GroupingComparator</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    <span class="keyword">super</span>(IntPair<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>)</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="comment">//Compare two WritableComparables.  </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable w1, WritableComparable w2)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    IntPair ip1 = (IntPair) w1;  </span><br><span class="line">    IntPair ip2 = (IntPair) w2;  </span><br><span class="line">    <span class="keyword">int</span> l = ip1.getFirst();  </span><br><span class="line">    <span class="keyword">int</span> r = ip2.getFirst();  </span><br><span class="line">    <span class="keyword">return</span> l == r ? <span class="number">0</span> : (l &lt; r ? -<span class="number">1</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">IntPair</span>, <span class="title">IntWritable</span>&gt;  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IntPair intkey = <span class="keyword">new</span> IntPair();  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IntWritable intvalue = <span class="keyword">new</span> IntWritable();  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    String line = value.toString();  </span><br><span class="line">    StringTokenizer tokenizer = <span class="keyword">new</span> StringTokenizer(line);  </span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">int</span> right = <span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">if</span> (tokenizer.hasMoreTokens())  </span><br><span class="line">    &#123;  </span><br><span class="line">    left = Integer.parseInt(tokenizer.nextToken());  </span><br><span class="line">    <span class="keyword">if</span> (tokenizer.hasMoreTokens())  </span><br><span class="line">    right = Integer.parseInt(tokenizer.nextToken());  </span><br><span class="line">    intkey.set(right, left);  </span><br><span class="line">    intvalue.set(left);  </span><br><span class="line">    context.write(intkey, intvalue);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">IntPair</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;  </span></span><br><span class="line"><span class="class">    </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Text left = <span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Text SEPARATOR = <span class="keyword">new</span> Text(<span class="string">"------------------------------------------------"</span>);  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntPair key, Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">    context.write(SEPARATOR, <span class="keyword">null</span>);  </span><br><span class="line">    left.set(Integer.toString(key.getFirst()));  </span><br><span class="line">    System.out.println(left);  </span><br><span class="line">    <span class="keyword">for</span> (IntWritable val : values)  </span><br><span class="line">    &#123;  </span><br><span class="line">    context.write(left, val);  </span><br><span class="line">    <span class="comment">//System.out.println(val);  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">    Job job = <span class="keyword">new</span> Job(conf, <span class="string">"secondarysort"</span>);  </span><br><span class="line">    job.setJarByClass(SecondarySort<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setPartitionerClass(FirstPartitioner<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setGroupingComparatorClass(GroupingComparator<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setMapOutputKeyClass(IntPair<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setMapOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    String[] otherArgs=<span class="keyword">new</span> String[<span class="number">2</span>];  </span><br><span class="line">    otherArgs[<span class="number">0</span>]=<span class="string">"hdfs://localhost:9000/mymapreduce8/in/goods_visit2"</span>;  </span><br><span class="line">    otherArgs[<span class="number">1</span>]=<span class="string">"hdfs://localhost:9000/mymapreduce8/out"</span>;  </span><br><span class="line">  </span><br><span class="line">    FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));  </span><br><span class="line">  </span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));  </span><br><span class="line">  </span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——倒排索引"><a href="#MapReduce实例——倒排索引" class="headerlink" title="MapReduce实例——倒排索引"></a>MapReduce实例——倒排索引</h5><h6 id="相关知识-8"><a href="#相关知识-8" class="headerlink" title="相关知识"></a>相关知识</h6><p>“倒排索引”是文档检索系统中最常用的数据结构，被广泛地应用于全文搜索引擎。它主要是用来存储某个单词（或词组）在一个文档或一组文档中的存储位置的映射，即提供了一种根据内容来查找文档的方式。由于不是根据文档来确定文档所包含的内容，而是进行相反的操作，因而称为倒排索引（Inverted Index）。</p>
<p>实现”倒排索引”主要关注的信息为：单词、文档URL及词频。</p>
<p>下面以本实验goods3、goods_visit3、order_items3三张表的数据为例，根据MapReduce的处理过程给出倒排索引的设计思路：</p>
<p>（1）Map过程</p>
<p>首先使用默认的TextInputFormat类对输入文件进行处理，得到文本中每行的偏移量及其内容。显然，Map过程首先必须分析输入的&lt;key,value&gt;对，得到倒排索引中需要的三个信息：单词、文档URL和词频，接着我们对读入的数据利用Map操作进行预处理，如下图所示：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<p>这里存在两个问题：第一，&lt;key,value&gt;对只能有两个值，在不使用Hadoop自定义数据类型的情况下，需要根据情况将其中两个值合并成一个值，作为key或value值。第二，通过一个Reduce过程无法同时完成词频统计和生成文档列表，所以必须增加一个Combine过程完成词频统计。</p>
<p>这里将商品ID和URL组成key值（如”1024600：goods3”），将词频（商品ID出现次数）作为value，这样做的好处是可以利用MapReduce框架自带的Map端排序，将同一文档的相同单词的词频组成列表，传递给Combine过程，实现类似于WordCount的功能。</p>
<p>（2）Combine过程</p>
<p>经过map方法处理后，Combine过程将key值相同的value值累加，得到一个单词在文档中的词频，如下图所示。如果直接将下图所示的输出作为Reduce过程的输入，在Shuffle过程时将面临一个问题：所有具有相同单词的记录（由单词、URL和词频组成）应该交由同一个Reducer处理，但当前的key值无法保证这一点，所以必须修改key值和value值。这次将单词（商品ID）作为key值，URL和词频组成value值（如”goods3：1”）。这样做的好处是可以利用MapReduce框架默认的HashPartitioner类完成Shuffle过程，将相同单词的所有记录发送给同一个Reducer进行处理。</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-1.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-1.png" alt="img"></a></p>
<p>（3）Reduce过程</p>
<p>经过上述两个过程后，Reduce过程只需将相同key值的所有value值组合成倒排索引文件所需的格式即可，剩下的事情就可以直接交给MapReduce框架进行处理了。如下图所示</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-2.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/1e88d94b-91ad-11e9-beeb-00215ec892f4/img/01-2.png" alt="img"></a></p>
<h6 id="code-1"><a href="#code-1" class="headerlink" title="code"></a>code</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyIndex</span> </span>&#123;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;  </span><br><span class="line">        Job job = Job.getInstance();  </span><br><span class="line">        job.setJobName(<span class="string">"InversedIndexTest"</span>);  </span><br><span class="line">        job.setJarByClass(MyIndex<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">        job.setMapperClass(doMapper<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setCombinerClass(doCombiner<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setReducerClass(doReducer<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">        job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">        Path in1 = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce9/in/goods3"</span>);  </span><br><span class="line">        Path in2 = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce9/in/goods_visit3"</span>);  </span><br><span class="line">        Path in3 = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce9/in/order_items3"</span>);  </span><br><span class="line">        Path out = <span class="keyword">new</span> Path(<span class="string">"hdfs://localhost:9000/mymapreduce9/out"</span>);  </span><br><span class="line">  </span><br><span class="line">        FileInputFormat.addInputPath(job, in1);  </span><br><span class="line">        FileInputFormat.addInputPath(job, in2);  </span><br><span class="line">        FileInputFormat.addInputPath(job, in3);  </span><br><span class="line">        FileOutputFormat.setOutputPath(job, out);  </span><br><span class="line">  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">doMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Text myKey = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Text myValue = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="comment">//private FileSplit filePath;  </span></span><br><span class="line">  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span>  </span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">            String filePath=((FileSplit)context.getInputSplit()).getPath().toString();  </span><br><span class="line">            <span class="keyword">if</span>(filePath.contains(<span class="string">"goods"</span>))&#123;  </span><br><span class="line">                String val[]=value.toString().split(<span class="string">"\t"</span>);  </span><br><span class="line">                <span class="keyword">int</span> splitIndex =filePath.indexOf(<span class="string">"goods"</span>);  </span><br><span class="line">                myKey.set(val[<span class="number">0</span>] + <span class="string">":"</span> + filePath.substring(splitIndex));  </span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(filePath.contains(<span class="string">"order"</span>))&#123;  </span><br><span class="line">                String val[]=value.toString().split(<span class="string">"\t"</span>);  </span><br><span class="line">                <span class="keyword">int</span> splitIndex =filePath.indexOf(<span class="string">"order"</span>);  </span><br><span class="line">                myKey.set(val[<span class="number">2</span>] + <span class="string">":"</span> + filePath.substring(splitIndex));  </span><br><span class="line">            &#125;  </span><br><span class="line">            myValue.set(<span class="string">"1"</span>);  </span><br><span class="line">            context.write(myKey, myValue);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">doCombiner</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Text myK = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Text myV = <span class="keyword">new</span> Text();  </span><br><span class="line">  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span> ;  </span><br><span class="line">    <span class="keyword">for</span> (Text value : values) &#123;  </span><br><span class="line">    sum += Integer.parseInt(value.toString());  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">int</span> mysplit = key.toString().indexOf(<span class="string">":"</span>);  </span><br><span class="line">    myK.set(key.toString().substring(<span class="number">0</span>, mysplit));  </span><br><span class="line">    myV.set(key.toString().substring(mysplit + <span class="number">1</span>) + <span class="string">":"</span> + sum);  </span><br><span class="line">    context.write(myK, myV);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">doReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Text myK = <span class="keyword">new</span> Text();  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Text myV = <span class="keyword">new</span> Text();  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span>  </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">  </span><br><span class="line">        String myList = <span class="keyword">new</span> String();  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">for</span> (Text value : values) &#123;  </span><br><span class="line">        myList += value.toString() + <span class="string">";"</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">        myK.set(key);  </span><br><span class="line">        myV.set(myList);  </span><br><span class="line">        context.write(myK, myV);  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实例——ChainMapReduce"><a href="#MapReduce实例——ChainMapReduce" class="headerlink" title="MapReduce实例——ChainMapReduce"></a>MapReduce实例——ChainMapReduce</h5><h6 id="相关知识-9"><a href="#相关知识-9" class="headerlink" title="相关知识"></a>相关知识</h6><p>一些复杂的任务难以用一次MapReduce处理完成，需要多次MapReduce才能完成任务。Hadoop2.0开始MapReduce作业支持链式处理，类似于工厂的生产线，每一个阶段都有特定的任务要处理，比如提供原配件——&gt;组装——打印出厂日期，等等。通过这样进一步的分工，从而提高了生成效率，我们Hadoop中的链式MapReduce也是如此，这些Mapper可以像水流一样，一级一级向后处理，有点类似于Linux的管道。前一个Mapper的输出结果直接可以作为下一个Mapper的输入，形成一个流水线。</p>
<p>链式MapReduce的执行规则：整个Job中只能有一个Reducer，在Reducer前面可以有一个或者多个Mapper，在Reducer的后面可以有0个或者多个Mapper。</p>
<p>Hadoop2.0支持的链式处理MapReduce作业有以下三种：</p>
<p>（1）顺序链接MapReduce作业</p>
<p>类似于Unix中的管道：mapreduce-1 | mapreduce-2 | mapreduce-3 ……，每一个阶段创建一个job，并将当前输入路径设为前一个的输出。在最后阶段删除链上生成的中间数据。</p>
<p>（2）具有复杂依赖的MapReduce链接</p>
<p>若mapreduce-1处理一个数据集， mapreduce-2 处理另一个数据集，而mapreduce-3对前两个做内部链接。这种情况通过Job和JobControl类管理非线性作业间的依赖。如x.addDependingJob(y)意味着x在y完成前不会启动。</p>
<p>（3）预处理和后处理的链接</p>
<p>一般将预处理和后处理写为Mapper任务。可以自己进行链接或使用ChainMapper和ChainReducer类，生成作业表达式类似于：</p>
<p>MAP+ | REDUCE | MAP*</p>
<p>如以下作业： Map1 | Map2 | Reduce | Map3 | Map4，把Map2和Reduce视为MapReduce作业核心。Map1作为前处理，Map3， Map4作为后处理。ChainMapper使用模式：预处理作业，ChainReducer使用模式：设置Reducer并添加后处理Mapper</p>
<p>本实验中用到的就是第三种作业模式：预处理和后处理的链接，生成作业表达式类似于 Map1 | Map2 | Reduce | Map3</p>
<h6 id="code-2"><a href="#code-2" class="headerlink" title="code"></a>code</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mapreduce;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.net.URI;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.chain.ChainMapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.chain.ChainReducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.partition.HashPartitioner;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.DoubleWritable;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChainMapReduce</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String INPUTPATH = <span class="string">"hdfs://localhost:9000/mymapreduce10/in/goods_0"</span>;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String OUTPUTPATH = <span class="string">"hdfs://localhost:9000/mymapreduce10/out"</span>;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">            FileSystem fileSystem = FileSystem.get(<span class="keyword">new</span> URI(OUTPUTPATH), conf);  </span><br><span class="line">            <span class="keyword">if</span> (fileSystem.exists(<span class="keyword">new</span> Path(OUTPUTPATH))) &#123;  </span><br><span class="line">                fileSystem.delete(<span class="keyword">new</span> Path(OUTPUTPATH), <span class="keyword">true</span>);  </span><br><span class="line">            &#125;  </span><br><span class="line">            Job job = <span class="keyword">new</span> Job(conf, ChainMapReduce<span class="class">.<span class="keyword">class</span>.<span class="title">getSimpleName</span>())</span>;  </span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(INPUTPATH));  </span><br><span class="line">            job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            ChainMapper.addMapper(job, FilterMapper1<span class="class">.<span class="keyword">class</span>, <span class="title">LongWritable</span>.<span class="title">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">conf</span>)</span>;  </span><br><span class="line">            ChainMapper.addMapper(job, FilterMapper2<span class="class">.<span class="keyword">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">conf</span>)</span>;  </span><br><span class="line">            ChainReducer.setReducer(job, SumReducer<span class="class">.<span class="keyword">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">conf</span>)</span>;  </span><br><span class="line">            ChainReducer.addMapper(job, FilterMapper3<span class="class">.<span class="keyword">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">Text</span>.<span class="title">class</span>, <span class="title">DoubleWritable</span>.<span class="title">class</span>, <span class="title">conf</span>)</span>;  </span><br><span class="line">            job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setMapOutputValueClass(DoubleWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setPartitionerClass(HashPartitioner<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setNumReduceTasks(<span class="number">1</span>);  </span><br><span class="line">            job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            job.setOutputValueClass(DoubleWritable<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(OUTPUTPATH));  </span><br><span class="line">            job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">            System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterMapper1</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="keyword">private</span> DoubleWritable outValue = <span class="keyword">new</span> DoubleWritable();  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, DoubleWritable&gt;.Context context)</span>  </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;  </span><br><span class="line">            String line = value.toString();  </span><br><span class="line">            <span class="keyword">if</span> (line.length() &gt; <span class="number">0</span>) &#123;  </span><br><span class="line">                String[] splits = line.split(<span class="string">"\t"</span>);  </span><br><span class="line">                <span class="keyword">double</span> visit = Double.parseDouble(splits[<span class="number">1</span>].trim());  </span><br><span class="line">                <span class="keyword">if</span> (visit &lt;= <span class="number">600</span>) &#123;  </span><br><span class="line">                    outKey.set(splits[<span class="number">0</span>]);  </span><br><span class="line">                    outValue.set(visit);  </span><br><span class="line">                    context.write(outKey, outValue);  </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterMapper2</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Text</span>, <span class="title">DoubleWritable</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Text key, DoubleWritable value, Mapper&lt;Text, DoubleWritable, Text, DoubleWritable&gt;.Context context)</span>  </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;  </span><br><span class="line">            <span class="keyword">if</span> (value.get() &lt; <span class="number">100</span>) &#123;  </span><br><span class="line">                context.write(key, value);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">DoubleWritable</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> DoubleWritable outValue = <span class="keyword">new</span> DoubleWritable();  </span><br><span class="line">        <span class="meta">@Override</span>  </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;DoubleWritable&gt; values, Reducer&lt;Text, DoubleWritable, Text, DoubleWritable&gt;.Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">double</span> sum = <span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">for</span> (DoubleWritable val : values) &#123;  </span><br><span class="line">    sum += val.get();  </span><br><span class="line">    &#125;  </span><br><span class="line">    outValue.set(sum);  </span><br><span class="line">    context.write(key, outValue);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterMapper3</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Text</span>, <span class="title">DoubleWritable</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Text key, DoubleWritable value, Mapper&lt;Text, DoubleWritable, Text, DoubleWritable&gt;.Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (key.toString().length() &lt; <span class="number">3</span>) &#123;  </span><br><span class="line">    System.out.println(<span class="string">"写出去的内容为："</span> + key.toString() +<span class="string">"++++"</span>+ value.toString());  </span><br><span class="line">    context.write(key, value);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h5 id="MapReduce实战PageRank算法"><a href="#MapReduce实战PageRank算法" class="headerlink" title="MapReduce实战PageRank算法"></a>MapReduce实战PageRank算法</h5><h6 id="相关知识-10"><a href="#相关知识-10" class="headerlink" title="相关知识"></a>相关知识</h6><p>PageRank：网页排名，右脚网页级别。是以Google 公司创始人Larry Page 之姓来命名。PageRank 计算每一个网页的PageRank值，并根据PageRank值的大小对网页的重要性进行排序。</p>
<p>PageRank的基本思想：</p>
<p>1.如果一个网页被很多其他网页链接到的话说明这个网页比较重要，也就是PageRank值会相对较高</p>
<p>2.如果一个PageRank值很高的网页链接到一个其他的网页，那么被链接到的网页的PageRank值会相应地因此而提高。</p>
<p>PageRank的算法原理：</p>
<p>PageRank算法总的来说就是预先给每个网页一个PR值，由于PR值物理意义上为一个网页被访问概率，所以一般是1/N，其中N为网页总数。另外，一般情况下，所有网页的PR值的总和为1。如果不为1的话也不是不行，最后算出来的不同网页之间PR值的大小关系仍然是正确的，只是不能直接地反映概率了。</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/01.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/01.png" alt="img"></a></p>
<p>如图，假设现在有四张网页，对于页面A来说，它链接到页面B，C，D，即A有3个出链，则它跳转到每个出链B，C，D的概率均为1/3.。如果A有k个出链，跳转到每个出链的概率为1/k。同理B到A，C，D的概率为1/2，0，1/2。C到A，B，D的概率为1，0，0。D到A，B，C的概率为0，1/2，1/2。</p>
<p>转化为矩阵为：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/02.jpg" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/02.jpg" alt="img"></a></p>
<p>在上图中，第一列为页面A对各个页面转移的概率，第一行为各个页面对页面A转移的概率。初始时，每一个页面的PageRank值都是均等的，为1/N，这里也即是1/4。然后对于页面A来说，根据每一个页面的PageRank值和每个页面对页面A的转移概率，可以算出新一轮页面A的PageRank值。这里，只有页面B转移了自己的1/2给A。页面C转移了自己的全部给A，所以新一轮A的PageRank值为1/4<em>1/2+1/4</em>1=9/24。</p>
<p>为了计算方便，我们设置各页面初始的PageRank值为一个列向量V0。然后再基于转移矩阵，我们可以直接求出新一轮各个页面的PageRank值。即 V1 = MV0</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/03.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/03.png" alt="img"></a></p>
<p>现在得到了各页面新的PageRank值V1, 继续用M 去乘以V1 ,就会得到更新的PageRank值。一直迭代这个过程，可以证明出V最终会收敛。此时停止迭代。这时的V就是各个页面的PageRank值。</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/04.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/04.png" alt="img"></a></p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/05.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/05.png" alt="img"></a></p>
<p>处理Dead Ends(终止点)：</p>
<p>上面的PageRank计算方法要求整个Web是强联通的。而实际上真实的Web并不是强联通的，有一类页面，它们不存在任何外链，对其他网页没有PR值的贡献，称之为Dead Ends(终止点)。如下图：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/06.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/06.png" alt="img"></a></p>
<p>这里页面C即是一个终止点。而上面的算法之所以能够成功收敛，很大因素上基于转移矩阵每一列的和为1（每一个页面都至少有一个出链）。当页面C没有出链时，转移矩阵M如下所示：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/07.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/07.png" alt="img"></a></p>
<p>基于这个转移矩阵和初始的PageRank列向量，每一次迭代过的PageRank列向量如下：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/08.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/08.png" alt="img"></a></p>
<p>解决该问题的一种方法是：迭代拿掉图中的Dead Ends点以及相关的边，之所以是迭代拿掉，是因为当拿掉最初的Dead Ends之后，又可能产生新的Dead Ends点。直到图中没有Dead Ends点为止。然后对剩余的所有节点，计算它们的PageRank ，然后以拿掉Dead Ends的逆序反推各个Dead Ends的PageRank值。</p>
<p>比如在上图中，首先拿掉页面C，发现没有产生新的Dead Ends。然后对A，B，D 计算他们的PageRank，他们初始PageRank值均为1/3，且A有两个出链，B有两个出链，D有一个出链，那么由上面的方法可以算出各页面最终的PageRank值。假设算出A的PageRank 为x，B的PageRank 为y，D的PageRank 为z，那么C的PageRank值为1/3<em>x + 1/2</em>z 。</p>
<p>处理Spider Traps（蜘蛛陷阱）：</p>
<p>真实的Web链接关系若是转换成转移矩阵，那必将是一个稀疏的矩阵。而稀疏的矩阵迭代相乘会使得中间产生的PageRank向量变得不平滑（一小部分值很大，大部分值很小或接近于0）。而一种Spider Traps节点会加剧这个不平滑的效果，也即是蜘蛛陷阱。它是指某一些页面虽然有外链，但是它只链向自己。如下图所示：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/09.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/09.png" alt="img"></a></p>
<p>如果对这个图按照上面的方法进行迭代计算PageRank ， 计算后会发现所有页面的PageRank值都会逐步转移到页面C上来，而其他页面都趋近于零。</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/10.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/10.png" alt="img"></a></p>
<p>为了解决这个问题，我们需要对PageRank 计算方法进行一个平滑处理–加入teleporting(跳转因子)。也就是说，用户在访问Web页面时，除了按照Web页面的链接关系进行选择以外，他也可能直接在地址栏上输入一个地址进行访问。这样就避免了用户只在一个页面只能进行自身访问，或者进入一个页面无法出来的情况。</p>
<p>加入跳转因子之后，PageRank向量的计算公式修正为：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/11.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/11.png" alt="img"></a></p>
<p>其中，β 通常设置为一个很小的数（0.2或者0.15），e为单位向量，N是所有页面的个数，乘以1/N是因为随机跳转到一个页面的概率是1/N。这样，每次计算PageRank值，既依赖于转移矩阵，同时依赖于小概率的随机跳转。</p>
<p>以上图为例，改进后的PageRank值计算如下：</p>
<p><a href="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/12.png" target="_blank" rel="noopener"><img src="https://insight.ipieuvre.com/doc/exper/28fcb358-91ad-11e9-beeb-00215ec892f4/img/12.png" alt="img"></a></p>
<p>按照这个计算公式迭代下去，会发现spider traps 效应被抑制了，使得各个页面得到一个合理的PageRank值。</p>
<h6 id="code-3"><a href="#code-3" class="headerlink" title="code"></a>code</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mr_pagerank;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PageRank</span> </span>&#123;  </span><br><span class="line">    <span class="comment">/*map过程*/</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">mapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>,<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="keyword">private</span> String id;  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">float</span> pr;  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> count;  </span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">float</span> average_pr;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,Text value,Context context)</span>  </span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException,InterruptedException</span>&#123;  </span><br><span class="line">            StringTokenizer str = <span class="keyword">new</span> StringTokenizer(value.toString());<span class="comment">//对value进行解析  </span></span><br><span class="line">            id =str.nextToken();<span class="comment">//id为解析的第一个词，代表当前网页  </span></span><br><span class="line">            pr = Float.parseFloat(str.nextToken());<span class="comment">//pr为解析的第二个词，转换为float类型，代表PageRank值  </span></span><br><span class="line">            count = str.countTokens();<span class="comment">//count为剩余词的个数，代表当前网页的出链网页个数  </span></span><br><span class="line">            average_pr = pr/count;<span class="comment">//求出当前网页对出链网页的贡献值  </span></span><br><span class="line">            String linkids =<span class="string">"&amp;"</span>;<span class="comment">//下面是输出的两类，分别有'@'和'&amp;'区分  </span></span><br><span class="line">            <span class="keyword">while</span>(str.hasMoreTokens())&#123;  </span><br><span class="line">                String linkid = str.nextToken();  </span><br><span class="line">                context.write(<span class="keyword">new</span> Text(linkid),<span class="keyword">new</span> Text(<span class="string">"@"</span>+average_pr));<span class="comment">//输出的是&lt;出链网页，获得的贡献值&gt;  </span></span><br><span class="line">                linkids +=<span class="string">" "</span>+ linkid;  </span><br><span class="line">            &#125;  </span><br><span class="line">            context.write(<span class="keyword">new</span> Text(id), <span class="keyword">new</span> Text(linkids));<span class="comment">//输出的是&lt;当前网页，所有出链网页&gt;  </span></span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">/*reduce过程*/</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">reduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">Text</span>,<span class="title">Text</span>&gt;</span>&#123;  </span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,Iterable&lt;Text&gt; values,Context context)</span>  </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException,InterruptedException</span>&#123;  </span><br><span class="line">    String link = <span class="string">""</span>;  </span><br><span class="line">    <span class="keyword">float</span> pr = <span class="number">0</span>;  </span><br><span class="line">    <span class="comment">/*对values中的每一个value进行分析，通过其第一个字符是'@'还是'&amp;'进行判断 </span></span><br><span class="line"><span class="comment">    通过这个循环，可以求出当前网页获得的贡献值之和，也即是新的PageRank值；同时求出当前 </span></span><br><span class="line"><span class="comment">    网页的所有出链网页 */</span>  </span><br><span class="line">    <span class="keyword">for</span>(Text val:values)&#123;  </span><br><span class="line">    <span class="keyword">if</span>(val.toString().substring(<span class="number">0</span>,<span class="number">1</span>).equals(<span class="string">"@"</span>))&#123;  </span><br><span class="line">    pr += Float.parseFloat(val.toString().substring(<span class="number">1</span>));  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(val.toString().substring(<span class="number">0</span>,<span class="number">1</span>).equals(<span class="string">"&amp;"</span>))&#123;  </span><br><span class="line">    link += val.toString().substring(<span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    pr = <span class="number">0.8f</span>*pr + <span class="number">0.2f</span>*<span class="number">0.25f</span>;<span class="comment">//加入跳转因子，进行平滑处理  </span></span><br><span class="line">    String result = pr+link;  </span><br><span class="line">    context.write(key, <span class="keyword">new</span> Text(result));  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;  </span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">    conf.set(<span class="string">"mapred.job.tracker"</span>, <span class="string">"hdfs://127.0.0.1:9000"</span>);  </span><br><span class="line">    <span class="comment">//设置数据输入路径  </span></span><br><span class="line">    String pathIn =<span class="string">"hdfs://127.0.0.1:9000/pagerank/input"</span>;  </span><br><span class="line">    <span class="comment">//设置数据输出路径  </span></span><br><span class="line">    String pathOut=<span class="string">"hdfs://127.0.0.1:9000/pagerank/output/pr"</span>;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;<span class="number">100</span>;i++)&#123;      <span class="comment">//加入for循环，最大循环100次  </span></span><br><span class="line">    Job job = <span class="keyword">new</span> Job(conf,<span class="string">"page rank"</span>);  </span><br><span class="line">    job.setJarByClass(PageRank<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setMapperClass(mapper<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setReducerClass(reduce<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    job.setOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(pathIn));  </span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(pathOut));  </span><br><span class="line">    pathIn = pathOut;<span class="comment">//把输出的地址改成下一次迭代的输入地址  </span></span><br><span class="line">    pathOut = pathOut+<span class="string">'-'</span>+i;<span class="comment">//把下一次的输出设置成一个新地址。  </span></span><br><span class="line">    System.out.println(<span class="string">"正在执行第"</span>+i+<span class="string">"次"</span>);  </span><br><span class="line">    job.waitForCompletion(<span class="keyword">true</span>);<span class="comment">//把System.exit()去掉  </span></span><br><span class="line">    <span class="comment">//由于PageRank通常迭代30~40次，就可以收敛，这里我们设置循环35次  </span></span><br><span class="line">    <span class="keyword">if</span>(i == <span class="number">35</span>)&#123;  </span><br><span class="line">    System.out.println(<span class="string">"总共执行了"</span>+i+<span class="string">"次之后收敛"</span>);  </span><br><span class="line">    <span class="keyword">break</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>








      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li></ul>

      
            
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/04/04/BigData/Sqoop-1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Sqoop介绍及库表操作
        
      </div>
    </a>
  
  
    <a href="/2020/03/26/BigData/Hadoopop%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hadoopop基础学习</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article" style="overflow-y: scroll; max-width: 28%;">
    <strong class="toc-title">Contents</strong>
    
      <ol class="nav"><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce学习——习题"><span class="nav-number">1.</span> <span class="nav-text">MapReduce学习——习题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——WordCount"><span class="nav-number">2.</span> <span class="nav-text">MapReduce实例——WordCount</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#任务目标"><span class="nav-number">2.1.</span> <span class="nav-text">任务目标</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识"><span class="nav-number">2.2.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#任务步骤"><span class="nav-number">2.3.</span> <span class="nav-text">任务步骤</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——去重"><span class="nav-number">3.</span> <span class="nav-text">MapReduce实例——去重</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#任务目标-1"><span class="nav-number">3.1.</span> <span class="nav-text">任务目标</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-1"><span class="nav-number">3.2.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#任务内容"><span class="nav-number">3.3.</span> <span class="nav-text">任务内容</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#任务步骤-1"><span class="nav-number">3.4.</span> <span class="nav-text">任务步骤</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——排序"><span class="nav-number">4.</span> <span class="nav-text">MapReduce实例——排序</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#任务目标-2"><span class="nav-number">4.1.</span> <span class="nav-text">任务目标</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-2"><span class="nav-number">4.2.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#任务内容-1"><span class="nav-number">4.3.</span> <span class="nav-text">任务内容</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#任务步骤-2"><span class="nav-number">4.4.</span> <span class="nav-text">任务步骤</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——求平均值"><span class="nav-number">5.</span> <span class="nav-text">MapReduce实例——求平均值</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-3"><span class="nav-number">5.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#代码"><span class="nav-number">5.2.</span> <span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——Reduce端join"><span class="nav-number">6.</span> <span class="nav-text">MapReduce实例——Reduce端join</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-4"><span class="nav-number">6.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#代码-1"><span class="nav-number">6.2.</span> <span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——Map端join"><span class="nav-number">7.</span> <span class="nav-text">MapReduce实例——Map端join</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-5"><span class="nav-number">7.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#代码-2"><span class="nav-number">7.2.</span> <span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——单表Join"><span class="nav-number">8.</span> <span class="nav-text">MapReduce实例——单表Join</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-6"><span class="nav-number">8.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#代码-3"><span class="nav-number">8.2.</span> <span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——二次排序"><span class="nav-number">9.</span> <span class="nav-text">MapReduce实例——二次排序</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-7"><span class="nav-number">9.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#code"><span class="nav-number">9.2.</span> <span class="nav-text">code</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——倒排索引"><span class="nav-number">10.</span> <span class="nav-text">MapReduce实例——倒排索引</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-8"><span class="nav-number">10.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#code-1"><span class="nav-number">10.2.</span> <span class="nav-text">code</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实例——ChainMapReduce"><span class="nav-number">11.</span> <span class="nav-text">MapReduce实例——ChainMapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-9"><span class="nav-number">11.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#code-2"><span class="nav-number">11.2.</span> <span class="nav-text">code</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MapReduce实战PageRank算法"><span class="nav-number">12.</span> <span class="nav-text">MapReduce实战PageRank算法</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#相关知识-10"><span class="nav-number">12.1.</span> <span class="nav-text">相关知识</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#code-3"><span class="nav-number">12.2.</span> <span class="nav-text">code</span></a></li></ol></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2020 Shaw All Rights Reserved.
          
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hiero" target="_blank">hiero</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->

<script src="/js/my.js"></script>

    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



  
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css">

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.js"></script>




<script src="/js/scripts.js"></script>


<script src="https://stackpath.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


<script src="/js/main.js"></script>








  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>








  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
