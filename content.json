{"meta":{"title":"Shaw","subtitle":"Do Your Best","description":"","author":null,"url":"http://yoursite.com","root":"/"},"pages":[{"title":"","date":"2020-03-19T07:32:05.721Z","updated":"2020-03-19T07:32:05.721Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-03-19T07:45:35.300Z","updated":"2020-03-19T07:45:35.300Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-19T08:07:06.921Z","updated":"2020-03-19T08:07:06.921Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2020-03-19T08:25:50.265Z","updated":"2020-03-19T08:25:50.265Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"hello world!!"}],"posts":[{"title":"Hadoop——MapReduce学习","slug":"BigData/Hadoop——MapReduce学习","date":"2020-03-26T00:51:50.000Z","updated":"2020-03-27T03:49:58.278Z","comments":true,"path":"2020/03/26/BigData/Hadoop——MapReduce学习/","link":"","permalink":"http://yoursite.com/2020/03/26/BigData/Hadoop%E2%80%94%E2%80%94MapReduce%E5%AD%A6%E4%B9%A0/","excerpt":"本章从MapReduce的原理、工作机制、应用开发、设计模式、算法时间和性能调优进行了详细的介绍 目标： 1、了解MapReduce原理(map函数、reduce函数、shuffle过程) 2、掌握MapReduce相关算法","text":"本章从MapReduce的原理、工作机制、应用开发、设计模式、算法时间和性能调优进行了详细的介绍 目标： 1、了解MapReduce原理(map函数、reduce函数、shuffle过程) 2、掌握MapReduce相关算法 MapReduce学习——习题1.对MapReduce的体系结构，以下说法正确的是： A.分布式编程架构 B.以数据为中心，更看重吞吐量 C.分而治之的思想 D.将一个任务分解成多个任务 2.MapReduce为了保证任务的正常执行，采用（）等多种容错机制 A.重复执行 B.重新开始整个任务 C.推测执行 D.直接丢弃执行效率低的作业 3.对Hadoop中JobTacker的工作角色，以下说法正确的是（） A.作业调度 B.分配任务 C.监控CPU运行效率 D.监控任务执行进度 4.在Hadoop中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker的负责作业的分解、状态监控以及资源管理 5.Map的主要工作是将任务分解成多个任务 MapReduce实例——WordCount任务目标1.准确理解Mapreduce的设计原理 2.熟练掌握WordCount程序代码编写 3.学会自己编写WordCount程序进行词频统计 相关知识MapReduce采用的是“分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个从节点共同完成，然后通过整合各个节点的中间结果，得到最终结果。简单来说，MapReduce就是”任务的分解与结果的汇总“。 1.MapReduce的工作原理 在分布式计算中，MapReduce框架负责处理了并行编程里分布式存储、工作调度，负载均衡、容错处理以及网络通信等复杂问题，现在我们把处理过程高度抽象为Map与Reduce两个部分来进行阐述，其中Map部分负责把任务分解成多个子任务，Reduce部分负责把分解后多个子任务的处理结果汇总起来，具体设计思路如下。 （1）Map过程需要继承org.apache.hadoop.mapreduce包中Mapper类，并重写其map方法。通过在map方法中添加两句把key值和value值输出到控制台的代码，可以发现map方法中输入的value值存储的是文本文件中的一行（以回车符为行结束标记），而输入的key值存储的是该行的首字母相对于文本文件的首地址的偏移量。然后用StringTokenizer类将每一行拆分成为一个个的字段，把截取出需要的字段（本实验为买家id字段）设置为key，并将其作为map方法的结果输出。 （2）Reduce过程需要继承org.apache.hadoop.mapreduce包中Reducer类，并重写其reduce方法。Map过程输出的&lt;key,value&gt;键值对先经过shuffle过程把key值相同的所有value值聚集起来形成values，此时values是对应key字段的计数值所组成的列表，然后将&lt;key,values&gt;输入到reduce方法中，reduce方法只要遍历values并求和，即可得到某个单词的总次数。 在main()主函数中新建一个Job对象，由Job对象负责管理和运行MapReduce的一个计算任务，并通过Job的一些方法对任务的参数进行相关的设置。本实验是设置使用将继承Mapper的doMapper类完成Map过程中的处理和使用doReducer类完成Reduce过程中的处理。还设置了Map过程和Reduce过程的输出类型：key的类型为Text，value的类型为IntWritable。任务的输出和输入路径则由字符串指定，并由FileInputFormat和FileOutputFormat分别设定。完成相应任务的参数设定后，即可调用job.waitForCompletion()方法执行任务，其余的工作都交由MapReduce框架处理。 2.MapReduce框架的作业运行流程 （1）ResourceManager：是YARN资源控制框架的中心模块，负责集群中所有资源的统一管理和分配。它接收来自NM(NodeManager)的汇报，建立AM，并将资源派送给AM(ApplicationMaster)。 （2）NodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器管理，并监控他们的资源使用情况（cpu、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。 （3）ApplicationMaster：以下简称AM。YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动Container，并告诉Container做什么事情。 （4）Container：资源容器。YARN中所有的应用都是在Container之上运行的。AM也是在Container上运行的，不过AM的Container是RM申请的。Container是YARN中资源的抽象，它封装了某个节点上一定量的资源（CPU和内存两类资源）。Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster。Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令（可以是任何命令，比如java、Python、C++进程启动命令均可）以及该命令执行所需的环境变量和外部资源（比如词典文件、可执行文件、jar包等）。 另外，一个应用程序所需的Container分为两大类，如下： ①运行ApplicationMaster的Container：这是由ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的ApplicationMaster所需的资源。 ②运行各类任务的Container：这是由ApplicationMaster向ResourceManager申请的，并为了ApplicationMaster与NodeManager通信以启动的。 以上两类Container可能在任意节点上，它们的位置通常而言是随机的，即ApplicationMaster可能与它管理的任务运行在一个节点上。 任务内容现有某电商网站用户对商品的收藏数据，记录了用户收藏的商品id以及收藏日期，名为buyer_favorite1 任务步骤12345678910111213141516171819#step1: 启动Hadoop#step2: 创建目录，下载数据文件#step3: 将linux本地&#x2F;data&#x2F;mapreduce1&#x2F;buyer_favorite1，上传到HDFS上的&#x2F;mymapreduce1&#x2F;in目录下hadoop fs -mkdir -p &#x2F;mymapreduce1&#x2F;in hadoop fs -put &#x2F;data&#x2F;mapreduce1&#x2F;buyer_favorite1 &#x2F;mymapreduce1&#x2F;in #step4: 打开Eclipse，新建Java Project项目,并将项目名设置为mapreduce1;在项目名mapreduce1下，新建package包,并将包命名为mapreduce;在创建的包mapreduce下，新建类,并将类命名为WordCount.#step5: 添加项目所需依赖的jar包,右键单击项目名，新建一个目录hadoop2lib，用于存放项目所需的jar包。#step6: 编写Java代码#step7: 在WordCount类文件中，单击右键&#x3D;&gt;Run As&#x3D;&gt;Run on Hadoop选项，将MapReduce任务提交到Hadoop中#step8: 待执行完毕后，打开终端或使用hadoop eclipse插件，查看hdfs上，程序输出的实验结果hadoop fs -ls &#x2F;mymapreduce1&#x2F;out hadoop fs -cat &#x2F;mymapreduce1&#x2F;out&#x2F;part-r-00000 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mapreduce; import java.io.IOException; import java.util.StringTokenizer; import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Job; import org.apache.hadoop.mapreduce.Mapper; import org.apache.hadoop.mapreduce.Reducer; import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; public class WordCount &#123; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Job job = Job.getInstance(); job.setJobName(\"WordCount\"); job.setJarByClass(WordCount.class); job.setMapperClass(doMapper.class); job.setReducerClass(doReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); Path in = new Path(\"hdfs://localhost:9000/mymapreduce1/in/buyer_favorite1\"); Path out = new Path(\"hdfs://localhost:9000/mymapreduce1/out\"); FileInputFormat.addInputPath(job, in); FileOutputFormat.setOutputPath(job, out); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125; public static class doMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123; public static final IntWritable one = new IntWritable(1); public static Text word = new Text(); @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; StringTokenizer tokenizer = new StringTokenizer(value.toString(), \"\\t\"); word.set(tokenizer.nextToken()); context.write(word, one); &#125; &#125; public static class doReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123; private IntWritable result = new IntWritable(); @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; int sum = 0; for (IntWritable value : values) &#123; sum += value.get(); &#125; result.set(sum); context.write(key, result); &#125; &#125; &#125; MapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCountMapReduce实例——WordCount","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://yoursite.com/tags/Hadoop/"}]},{"title":"Hadoopop基础学习","slug":"BigData/Hadoopop基础学习","date":"2020-03-26T00:51:23.000Z","updated":"2020-03-26T00:51:23.868Z","comments":true,"path":"2020/03/26/BigData/Hadoopop基础学习/","link":"","permalink":"http://yoursite.com/2020/03/26/BigData/Hadoopop%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hadoop——HDFS学习","slug":"BigData/Hadoop——HDFS学习","date":"2020-03-26T00:51:05.000Z","updated":"2020-03-26T01:09:03.815Z","comments":true,"path":"2020/03/26/BigData/Hadoop——HDFS学习/","link":"","permalink":"http://yoursite.com/2020/03/26/BigData/Hadoop%E2%80%94%E2%80%94HDFS%E5%AD%A6%E4%B9%A0/","excerpt":"HDFS理论讲解HDFS理论讲解分布式结构集群和分布式概念集群：指逻辑上处理同一任务的机器集合，可以属于同意机房，也可分属不同机房。 分布式：分布式文件系统把文件分布存储到多个计算机节点上，成千上万的计算机节点构成计算机集群。","text":"HDFS理论讲解HDFS理论讲解分布式结构集群和分布式概念集群：指逻辑上处理同一任务的机器集合，可以属于同意机房，也可分属不同机房。 分布式：分布式文件系统把文件分布存储到多个计算机节点上，成千上万的计算机节点构成计算机集群。 计算机集群基本架构： 。。。。。。。图。。。。。。。 目前的分布式文件系统所采用的计算机集群，都是由普通硬件构成，大大降低了硬件上的开销 分布式文件系统的结构HDFS架构和相关概念HDFS数据操作HDFS数据处理原理HDFS基本操作HDFS目录文件HDFS文件操作HDFS查看文件信息HDFS压缩与解压缩HDFS数据读写过程HDFS数据读写过程","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://yoursite.com/tags/Hadoop/"}]},{"title":"Linux常用命令——系统介绍","slug":"Linux/Linux常用命令——系统介绍","date":"2020-03-25T04:26:16.000Z","updated":"2020-03-25T04:31:36.554Z","comments":true,"path":"2020/03/25/Linux/Linux常用命令——系统介绍/","link":"","permalink":"http://yoursite.com/2020/03/25/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"简介开源软件应用领域学习方法与WIN的不同123456789Linux严格区分大小写Linux中所有内容跟以文件形式保存，包括硬件Linux不靠扩展名区分文件类型 压缩包:&quot;*.gz&quot; &quot;*.bz2&quot; &quot;*.tar.bz2&quot; &quot;*.tgz&quot;等 二进制软件包:&quot;.rpm&quot; 网页文件:&quot;*.html&quot; &quot;*.php&quot; 脚本文件:&quot;*.sh&quot; 配置文件:&quot;*.conf&quot;Windows下的程序不能直接在Linux中安装和运行 字符界面的优势121.占用的系统资源更少2.减少了出错、被攻击的可能","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Linux常用命令——用户操作","slug":"Linux/Linux常用命令——用户操作","date":"2020-03-25T04:25:54.000Z","updated":"2020-03-25T04:29:30.034Z","comments":true,"path":"2020/03/25/Linux/Linux常用命令——用户操作/","link":"","permalink":"http://yoursite.com/2020/03/25/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C/","excerpt":"查看登录用户命令12345678910w 用户名命令输出： USER:登录的用户名 TTY:登陆终端 FROM:IP地址登录 LOGIN@:登陆时间 IDLE:用户闲置时间 JCPU:指的时和该终端连接的所有进程的占用时间。不包括后台时间，但却包括当前正在运行的后台作业所占用的时间。 PCPU:指当前进程所占用的时间 WHAT:当前正在运行的命令","text":"查看登录用户命令12345678910w 用户名命令输出： USER:登录的用户名 TTY:登陆终端 FROM:IP地址登录 LOGIN@:登陆时间 IDLE:用户闲置时间 JCPU:指的时和该终端连接的所有进程的占用时间。不包括后台时间，但却包括当前正在运行的后台作业所占用的时间。 PCPU:指当前进程所占用的时间 WHAT:当前正在运行的命令 查看登录用户信息12345who 用户名命令输出: -用户名 -登陆终端 -登陆时间(登陆来源IP地址) 查询当前登录和过去的登陆的用户信息12345678last#last命令默认是读取&#x2F;var&#x2F;log&#x2F;wtmp文件数据命令输出： -用户名 -登陆终端 -登录IP -登陆时间 -退出时间(在线时间)","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Linux常用命令——文件目录操作","slug":"Linux/Linux常用命令——文件目录操作","date":"2020-03-25T04:25:43.000Z","updated":"2020-03-25T04:30:34.591Z","comments":true,"path":"2020/03/25/Linux/Linux常用命令——文件目录操作/","link":"","permalink":"http://yoursite.com/2020/03/25/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E6%93%8D%E4%BD%9C/","excerpt":"命令格式命令提示符123456[root@localhost ~]# root: 当前登录用户 localhost: 主机名 ~: 当前所在目录(家目录) #: 超级用户的提示符 $: 普通用户提示符","text":"命令格式命令提示符123456[root@localhost ~]# root: 当前登录用户 localhost: 主机名 ~: 当前所在目录(家目录) #: 超级用户的提示符 $: 普通用户提示符 命令格式12命令 [选项] [参数]注意：个别命令使用不遵循此格式，当有多个选项时，可以写在一起简化选项与完整选项 -a &lt;&#x3D;&#x3D;&gt; --all 查询目录中内容:ls123456789101112131415161718192021222324ls [option] [file&#x2F;catalogue][options]: -a:显示所有文件，包括隐藏文件 -l:显示详细信息 -d:查看目录属性 -h:人性化显示文件大小 -i:显示inode-rw-r--r-- -文件类型(-文件 d目录 l软连接文件) 其他文件类型: 块设备文件、字符设备文件、套接字文件和管道文件 rw- r-- r-- u所有者 g所属组 o其他人r:读w:写x:执行-rw-------. 1 root root 1207 1月 14 18:18 anaconda-ks.cfg . : ACL权限 1 : 引用计数，文件被调用次数 root: 文件主人 root: 所属组 1207: 文件大小(byte)(ls -lh:显示人能看得懂的) 1月 14 18:18: 最后一次修改时间 目录处理命令建立目录: mkdir12mkdir -p [目录名] -p 递归创建 切换所在目录: cd1234567cd [目录]简化操作： cd ~ :进入当前用户的家目录 cd : cd - :进入上次目录 cd ..:进入上一级目录 cd . :进入当前目录 查询所在目录位置: pwd1pwd :print working directory 删除空目录: rmdir1rmdir [目录名] : remove empty directories 删除文件或目录: rm1234rm -rf [文件或目录]rm -rf &#x2F; #删除根目录下所有文件--自杀 -r: 删除目录 -f: 强制 复制命令 :cp123456cp [options] [orgfile&#x2F;catelogue] [target_catelogue][options]: -r:复制目录 -p:连带文件属性复制 -d:若源文件时链接文件，则复制链接属性 -a:相当于 -pdr 剪切或改名命令 : mv1mv [原文件或者目录] [目标目录] 常见目录作用12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost &#x2F;]# lsbin :命令保存目录（普通用户就可以读取命令）sbin:命令保存目录(super_user才能使用)cgroup:etc:配置文件保存目录lib:系统库保存目录media:挂载目录mnt:系统挂载目录opt:root:超级用户的家目录selinux:sys:usr:boot:启动目录，启动相关文件dev:设备文件保存目录(别动)home:普通用户的家目录lost+found:misc:net:proc:直接写入内存srv:tmp:临时目录var:系统相关文档目录#proc和sys目录不能直接操作，这两个目录保存的时内存的过载点[root@localhost &#x2F;]# ls usr&#x2F;bin:etc:games:include:lib:libexec:local:sbin:share:src:tmp:#根目录下的bin和sbin,usr目录下的bin和sbin,这四个目录都是用来保存系统命令的 链接命令连接命令:ln123ln -s [原文件] [目标文件][options]: -s 创建软连接 硬链接特征12341.拥有相同的i节点和存储block块，可以看作时同一个文件2.可通过i节点识别3.不能跨分区4.不能针对目录使用 软连接特征123451.类似windows快捷方式2.软连接拥有自己的I节点和block块，但是数据块中只保存文件的文件名和I节点号，但没有实际的文件书数据3.lrwxrwxrwx l软连接：软连接的文件权限都为rwxrwxrwx4.修改任意文件，另一个都改变5.删除原文件，软连接不能使用","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Linux——文件搜索命令","slug":"Linux/Linux常用命令——文件搜索命令","date":"2020-03-24T14:14:18.000Z","updated":"2020-03-24T15:11:07.815Z","comments":true,"path":"2020/03/24/Linux/Linux常用命令——文件搜索命令/","link":"","permalink":"http://yoursite.com/2020/03/24/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E6%96%87%E4%BB%B6%E6%90%9C%E7%B4%A2%E5%91%BD%E4%BB%A4/","excerpt":"文件搜索命令(比windows强大)文件搜索命令locate （搜索速度较快，但只能按照文件名搜索）locate命令格式 123456# 在后台数据库中按照文件名搜索，搜 索速度更快locate 文件名#locate命令搜索的后台数据库(Linux版本不同数据库的名称可能不同)&#x2F;var&#x2F;lib&#x2F;mlocate#若要查询当天新建数据库，需要强制更新数据库updatedb","text":"文件搜索命令(比windows强大)文件搜索命令locate （搜索速度较快，但只能按照文件名搜索）locate命令格式 123456# 在后台数据库中按照文件名搜索，搜 索速度更快locate 文件名#locate命令搜索的后台数据库(Linux版本不同数据库的名称可能不同)&#x2F;var&#x2F;lib&#x2F;mlocate#若要查询当天新建数据库，需要强制更新数据库updatedb /etc/updatedb.conf配置文件 12345678#开启搜索限制，YES表示以下规则全都生效PRUNE_BIND_MOUNTS &#x3D; &quot;yes&quot;#搜索时，不搜索文件系统PRUNEFS&#x3D;#搜索时，不搜索文件类型PRUNENAMES&#x3D;#搜索时，不搜索的路径PRUNEPATHS&#x3D; 命令搜索命令whereis、which1234#whereis 命令名 (只能查询系统文件) -b: 只查找可执行文件 -m: 只查找帮助文件#which 命令名 (位置+别名&lt;非所有命令&gt;) PATH环境变量12#定义用户操作环境的变量(定义的是系统搜索命令的路径)echo $PATH 文件搜索命令find (所有文件进行遍历)find 完全匹配 find命令 1234567#搜索文件find [搜索范围] [搜索条件]#避免大范围搜索，会非常消耗系统资源#find是在系统当中搜索符合体哦阿健的文件名。如果需要匹配，使用通配符匹配，通配符是完全匹配find &#x2F; -name install.log#搜索以c结尾或者以d结尾find &#x2F;root -name &quot;*[cd]&quot; Linux中的通配符 12345*： 匹配任意内容?: 匹配任意一个字符[]: 匹配任意一个中括号内的字符 find命令eg 12345678910111213141516171819202122232425262728293031#不区分大小写find &#x2F;root -iname install.log#按照所有者搜索find &#x2F;root -user root#查找没有所有者的文件find &#x2F;root -nouser#查找10天前修改的文件find &#x2F;var&#x2F;log&#x2F; -mtime +10 -10:10天内修改文件 10: 10天当天修改的文件 +10: 10天前修改的文件 atime: 文件访问时间 ctime: 改变文件属性 mtime: 修改文件内容#查找文件大小是25KB的文件find . -size 25K -25k: 小于25KB的文件 25: 等于25kb的文件 +25: 大于25KB的文件#大小为数据块，根据扇区find &#x2F;root -size 25#查找i节点是262422的文件ls -i find . -inum 262422#查找&#x2F;etc&#x2F;目录下，大于20kb并且小于50kb的文件find &#x2F;etc -size _20k -a -size -50k -a and -o or#查找&#x2F;etc&#x2F;目录下，大于20kb并且小于50kb的文件，显示详细信息#-exec&#x2F;-ok 命令 &#123;&#125; \\; 对搜索结果执行操作find &#x2F;etc -size _20k -a -size -50k -exec ls -lh &#123;&#125; \\; 字符串搜索命令grepgrep 包含匹配 12345#在文件中匹配符合条件的字符串grep [option] string filename[option]: -i 忽略大小写 -v 排除指定字符串 grep-eg 123456#查看sizegrep &quot;size&quot; anaconda-ks.cfggrep -v &quot;size&quot; anaconda-ks.cfg[options]: -v: 取反 find与grep的区别12find:在系统中搜索符合条件的文件名，如果需要匹配使用通配符匹配，通配符是完全匹配grep:在文件中搜索符合条件的字符串，如果需要匹配，使用正则表达式进行匹配，正则表达式时包含匹配。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Linux常用命令——压缩与解压操作","slug":"Linux/Linuxux常用命令——压缩与解压操作","date":"2020-03-23T05:11:02.000Z","updated":"2020-03-24T15:11:39.340Z","comments":true,"path":"2020/03/23/Linux/Linuxux常用命令——压缩与解压操作/","link":"","permalink":"http://yoursite.com/2020/03/23/Linux/Linuxux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E5%8E%8B%E7%BC%A9%E4%B8%8E%E8%A7%A3%E5%8E%8B%E6%93%8D%E4%BD%9C/","excerpt":"常用的压缩格式： .zip .rar .bz2 .tar.gz .tar.bz2 //按照压缩格式记相关命令相对方便 .zip格式压缩 &amp; 解压缩121. Linux 不严格区分压缩文件名，压缩文件不一定比源文件小(压缩文件大小 &#x3D; 源文件大小 + 压缩格式)2. Linux中只要是压缩包，都以红色显示 123456#压缩文件zip new_file.zip org_file#压缩目录zip -r new_file.zip org_file#解压缩unzip name.zip（压缩文件）","text":"常用的压缩格式： .zip .rar .bz2 .tar.gz .tar.bz2 //按照压缩格式记相关命令相对方便 .zip格式压缩 &amp; 解压缩121. Linux 不严格区分压缩文件名，压缩文件不一定比源文件小(压缩文件大小 &#x3D; 源文件大小 + 压缩格式)2. Linux中只要是压缩包，都以红色显示 123456#压缩文件zip new_file.zip org_file#压缩目录zip -r new_file.zip org_file#解压缩unzip name.zip（压缩文件） .gz格式压缩&amp;解压缩(windows适用)123456#压缩为.gz格式的压缩文件，源文件会消失gzip org_file#压缩为.gz格式的压缩文件，源文件保留gzip -c org_file &gt; new_file.gz#压缩目录下所有子文件，但不能压缩目录gzip -r catalogue 1234#解压缩文件gzip -d file.gzgunzip file.gzgunzip -r file.gz .bz2格式压缩（不能压缩目录）1234#压缩.bz2格式，不保留源文件bzip2 org_file#压缩后保留源文件bzip -k org_file","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Linuxux常用命令——帮助命令","slug":"Linux/Linuxux常用命令——帮助命令","date":"2020-03-23T05:10:35.000Z","updated":"2020-03-24T15:11:23.318Z","comments":true,"path":"2020/03/23/Linux/Linuxux常用命令——帮助命令/","link":"","permalink":"http://yoursite.com/2020/03/23/Linux/Linuxux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E2%80%94%E2%80%94%E5%B8%AE%E5%8A%A9%E5%91%BD%E4%BB%A4/","excerpt":"帮助命令 man（manual）man 命令12#man - format and display the on-line manual pages#man [-acdfFhkKtwW] [--path] [-m system] [-p string] [-c config file] [-M pathlist] [-P pager] [-B bowser] [-H htmlpager] [-S section list] [section] name ... 查看快捷键或方式12输入 &#x2F;-d #找到第一个dn #next 翻页","text":"帮助命令 man（manual）man 命令12#man - format and display the on-line manual pages#man [-acdfFhkKtwW] [--path] [-m system] [-p string] [-c config file] [-M pathlist] [-P pager] [-B bowser] [-H htmlpager] [-S section list] [section] name ... 查看快捷键或方式12输入 &#x2F;-d #找到第一个dn #next 翻页 man的级别1234567891: 查看命令帮助2: 查看可被内核调用的函数的帮助3: 查看函数和函数库的帮助4: 查看特殊文件的帮助(主要是&#x2F;dev目录下的文件)5: 查看配置文件的帮助6: 查看游戏的帮助7: 查看其他杂项的帮助8: 查看系统管理员可用命令的帮助9: 查看和内核相关文件的帮助 查看命令拥有那个级别的帮助12345man -f 命令 &lt;&#x3D;&#x3D;&gt; whatis passwdeg: man -5 passwd #5等级帮助 man -1 passwd #1等级帮助 man -4 null man -8 ifconfig 查看和命令相关的所有帮助1man -k 命令 &lt;&#x3D;&#x3D;&gt; apropos 命令 选项帮助123#获取命令选项的帮助命令 --helpeg: ls --help shell内部命令帮助1234567#获取shell内部命令help shell内部命令eg: whereis cd #确定是否是shell内部命令，判断（无有可执行文件，则为内部命令）help cd #内部命令 不能 man shell内部命令#help 只能获取内部命令 详细命令帮助info123456info 命令 -Enter: 进入子帮助页面（带有*号标记） -u: 进入上层页面 -n: 进入下一个帮助小节 -p: 进入上一个帮助小节 -q: 退出","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"http://yoursite.com/tags/Linux%E5%91%BD%E4%BB%A4/"}]},{"title":"Windows 10下进行MySQL数据文件的转移","slug":"databases/mysql-data迁移","date":"2020-03-19T02:09:04.922Z","updated":"2020-03-19T06:46:57.625Z","comments":true,"path":"2020/03/19/databases/mysql-data迁移/","link":"","permalink":"http://yoursite.com/2020/03/19/databases/mysql-data%E8%BF%81%E7%A7%BB/","excerpt":"​ 在进行数据分析的过程中，“基石”便是数据，可在使用过程中，存储在某个盘中的数据会不断累积，特别是MySQL的默认安装路径为C盘(C:\\Program Files\\MySQL\\MySQL Server 8.0)，将会导致C盘内存越用越小。同时个人因为各种需求也需要进行数据文件的转移。 转移文件12345** windows下数据文件为隐藏文件 基本都在 C:\\ProgramData 该路径下 **Step1:找到 C:\\ProgramData\\MySQL\\MySQL Server 8.0 下的 Data 文件Setp2: 复制Data文件到 转移目标路径下 F:\\Data\\MySQL Server 8.0\\ --&gt; F:\\Data\\MySQL Server 8.0\\Data","text":"​ 在进行数据分析的过程中，“基石”便是数据，可在使用过程中，存储在某个盘中的数据会不断累积，特别是MySQL的默认安装路径为C盘(C:\\Program Files\\MySQL\\MySQL Server 8.0)，将会导致C盘内存越用越小。同时个人因为各种需求也需要进行数据文件的转移。 转移文件12345** windows下数据文件为隐藏文件 基本都在 C:\\ProgramData 该路径下 **Step1:找到 C:\\ProgramData\\MySQL\\MySQL Server 8.0 下的 Data 文件Setp2: 复制Data文件到 转移目标路径下 F:\\Data\\MySQL Server 8.0\\ --&gt; F:\\Data\\MySQL Server 8.0\\Data 关闭MySQL服务1net stop mysql80 更改配置——数据存储路径&lt; img src=”1.PNG” alt=”post-cover”&gt; 1234567Step1:找到 C:\\ProgramData\\MySQL\\MySQL Server 8.0\\my.ini 打开文件进行编辑Setp2: # Path to the database root#datadir&#x3D;C:&#x2F;ProgramData&#x2F;MySQL&#x2F;MySQL Server 8.0&#x2F;Data ⬇ (将上面原路径注释，插入转移的目标路径)datadir&#x3D;F:&#x2F;Data&#x2F;MySQL Server 8.0&#x2F;Data 启动MySQL服务1net start mysql80 测试通过新建DataBases，查看文件是否新建文件 123#进入mysqlmysql -u root -pcreate databases test;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL Server","slug":"MySQL-Server","permalink":"http://yoursite.com/tags/MySQL-Server/"}]},{"title":"2020-3-18","slug":"study english/2020-3-18","date":"2020-03-18T11:26:06.000Z","updated":"2020-03-18T11:30:23.944Z","comments":true,"path":"2020/03/18/study english/2020-3-18/","link":"","permalink":"http://yoursite.com/2020/03/18/study%20english/2020-3-18/","excerpt":"","text":"Pain is the breaking of the shell that encloses your understanding.","categories":[{"name":"Daily Sentence","slug":"Daily-Sentence","permalink":"http://yoursite.com/categories/Daily-Sentence/"}],"tags":[{"name":"Daily Sentence","slug":"Daily-Sentence","permalink":"http://yoursite.com/tags/Daily-Sentence/"}]},{"title":"深度学习.pdf","slug":"books/深度学习参考书籍","date":"2020-03-15T08:48:42.885Z","updated":"2020-03-19T05:01:07.041Z","comments":true,"path":"2020/03/15/books/深度学习参考书籍/","link":"","permalink":"http://yoursite.com/2020/03/15/books/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%82%E8%80%83%E4%B9%A6%E7%B1%8D/","excerpt":"","text":"","categories":[{"name":"BOOKS","slug":"BOOKS","permalink":"http://yoursite.com/categories/BOOKS/"}],"tags":[{"name":"MyBooks","slug":"MyBooks","permalink":"http://yoursite.com/tags/MyBooks/"}]},{"title":"2020-3-9 (From Criminal Minds)","slug":"study english/2020-3-9","date":"2020-03-09T14:27:56.928Z","updated":"2020-03-09T14:44:03.092Z","comments":true,"path":"2020/03/09/study english/2020-3-9/","link":"","permalink":"http://yoursite.com/2020/03/09/study%20english/2020-3-9/","excerpt":"","text":"Better to write for youself and have no public.Then to write for the public and have noself.","categories":[{"name":"Daily Sentence","slug":"Daily-Sentence","permalink":"http://yoursite.com/categories/Daily-Sentence/"}],"tags":[{"name":"Daily Sentence","slug":"Daily-Sentence","permalink":"http://yoursite.com/tags/Daily-Sentence/"}]},{"title":"基于维基百科中文语料库的Word2Vec模型训练","slug":"NLP/nlp1","date":"2020-03-09T07:42:53.479Z","updated":"2020-03-09T08:04:01.803Z","comments":true,"path":"2020/03/09/NLP/nlp1/","link":"","permalink":"http://yoursite.com/2020/03/09/NLP/nlp1/","excerpt":"说明：该博客代码参考于参考博客：使用中文维基百科语料库+opencc+jieba+gensim训练一个word2vec模型参考博客：使用中文维基百科训练word2vec模型 零、 模型训练环境 Windows10-X64 、 python2.7 、 python3.6 pip install jieba pip install gensim","text":"说明：该博客代码参考于参考博客：使用中文维基百科语料库+opencc+jieba+gensim训练一个word2vec模型参考博客：使用中文维基百科训练word2vec模型 零、 模型训练环境 Windows10-X64 、 python2.7 、 python3.6 pip install jieba pip install gensim 一、下载维基百科语料库数据下载地址该博客使用的是 24-Nov-2019 的语料库 二、 利用WikiExtractor.py抽取正文WikiExtractor.py Copy链接直接把py文件中的源码直接复制到新的 .py 中即可。下图是模型训练相关文件：执行命令 1python WiKiExtractor.py -b 500M -o zhwiki zhwiki-20191120-pages-articles-multistream.xml.bz2 我们最终会生成zhwiki文件夹得到三个文本文件 ./zhwiki/AA/wiki_00./zhwiki/AA/wiki_01./zhwiki/AA/wiki_02 三、 中文繁体转换成简体简体直接使用开源项目转换工具opencc转换工具下载地址黑框框起来的是我下载的版本 执行文件添加到环境变量中：方法1. 解压后将该工具bin目录添加到环境变量中方法2. 有些工具解压后灭有 bin 目录，我们首先找到opencc.exe可执行文件，将其路径添加到环境变量中 运行命令我是在该路径中运行的命令，为了方便我先将之前的三个文件拷贝到该路径下，执行完后再拷贝到./zhwiki/ 下。 123.\\opencc -i wiki_00 -o zh_wiki_00 -c /path/to/t2s.json.\\opencc -i wiki_01 -o zh_wiki_01 -c /path/to/t2s.json.\\opencc -i wiki_02 -o zh_wiki_02 -c /path/to/t2s.json 最终我把生成的zh_wiki_00等文件拷贝到 /zhwiki/ 中 四、符号处理 ，整合文件python 2.7 环境中运行exec_sum.py 1234567891011121314151617181920212223242526#!python2import reimport sysimport codecsdef myfun(input_file): p1 = re.compile(ur'-\\&#123;.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\\&#125;-') p2 = re.compile(ur'[（\\(][，；。？！\\s]*[）\\)]') p3 = re.compile(ur'[「『]') p4 = re.compile(ur'[」』]') outfile = codecs.open('std_zh_wiki', 'a+', 'utf-8') with codecs.open(input_file, 'r', 'utf-8') as myfile: for line in myfile: line = p1.sub(ur'\\2', line) line = p2.sub(ur'', line) line = p3.sub(ur'“', line) line = p4.sub(ur'”', line) outfile.write(line) outfile.close()if __name__ == '__main__': if len(sys.argv) != 2: print(\"Usage: python script.py inputfile\") sys.exit() reload(sys) sys.setdefaultencoding('utf-8') input_file = sys.argv[1] myfun(input_file) 方法一：将三个文件处理后追加到一个文件中即 std_zh_wiki 123python .\\exec_sum.py zh_wiki_00python .\\exec_sum.py zh_wiki_01python .\\exec_sum.py zh_wiki_02 方法二：我是使用 pycharm IDE 运行了 三次该文件，每次运行修改 input_file(zh_wiki_00、zh_wiki_01、zh_wiki_02) (更改python环境更方便) 五、jieba 分词操作exec_cut.py 123456789101112131415161718192021222324252627282930313233343536import logging, jieba, os, redef get_stopwords(): logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO) # 加载停用词表 stopword_set = set() with open(\"stopwords.txt\", 'r') as stopwords: for stopword in stopwords: stopword_set.add(stopword.strip(\"\\n\")) return stopword_setdef parse_zhwiki(read_file_path, save_file_path): # 过滤掉&lt;doc&gt; regex_str = \"[^&lt;doc.*&gt;$]|[^&lt;/doc&gt;$]\" file = open(read_file_path, \"r\") output = open(save_file_path, \"w+\") content_line = file.readline() stopwords = get_stopwords() article_contents = \"\" while content_line: match_obj = re.match(regex_str, content_line) content_line = content_line.strip(\"\\n\") if len(content_line) &gt; 0: if match_obj: words = jieba.cut(content_line, cut_all=False) for word in words: if word not in stopwords: article_contents += word + \" \" else: if len(article_contents) &gt; 0: output.write(article_contents.encode('utf-8','ignore')+ \"\\n\") article_contents = \"\" content_line = file.readline() output.close()parse_zhwiki('./std_zh_wiki', './cut_std_zh_wiki') 该操作也是在 python 2.7环境下操作 分词时间相对较长，请耐心等待 六、 训练Word2Vec模型1234567from gensim.models import word2vecimport logginglogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)sentences = word2vec.LineSentence('./cut_std_zh_wiki')model = word2vec.Word2Vec(sentences,size=200,window=5,min_count=5,workers=4)model.save('WikiCHModel') 训练完后，会生成三个文件 如果python3环境下出现编码问题，请通过某些工具将文件转换成utf-8编码 如果无法更改编码，请使用python2.7 七、 模型测试123456from gensim.models import word2vecimport loggingfrom gensim import modelsmodel = word2vec.Word2Vec.load('WikiCHModel')print(model.wv.similarity(\"儿童\", '狗')) #两个词的相关性 若博客中内容存在问题，可在评论处留言，本人将及时更正相关内容","categories":[{"name":"NLP(自然语言处理)","slug":"NLP-自然语言处理","permalink":"http://yoursite.com/categories/NLP-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"}],"tags":[{"name":"NLP(自然语言处理)","slug":"NLP-自然语言处理","permalink":"http://yoursite.com/tags/NLP-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"}]},{"title":"解决NLTK语料库下载出错及nltk_data路径等问题","slug":"NLP/nlp_nltk","date":"2020-03-09T07:23:49.285Z","updated":"2020-03-09T07:26:00.996Z","comments":true,"path":"2020/03/09/NLP/nlp_nltk/","link":"","permalink":"http://yoursite.com/2020/03/09/NLP/nlp_nltk/","excerpt":"一、解决NLTK语料库下载问题NLTK有许多可供使用的语料库，但直接通过官网下载会出现某些问题下载语料库代码 12import nltknltk.download(\"all\") 代码中添加的参数可参考官方链接","text":"一、解决NLTK语料库下载问题NLTK有许多可供使用的语料库，但直接通过官网下载会出现某些问题下载语料库代码 12import nltknltk.download(\"all\") 代码中添加的参数可参考官方链接 问题一：下载速度过慢，考验你的耐心 问题二：下载速度过慢导致下载中止，再次运行命令会导致下图情况 解决方案：通过百度资源下载nltk_data链接：nltk_data提取码：ucun 二、nltk_data路径问题1.直接解压在C盘根目录下(C:\\nltk_data)测试代码 1234from nltk.book import *from nltk.corpus import reutersfiles = reuters.fileids()print(files) 2.放在任意目录下:测试代码 123456from nltk import datafrom nltk.corpus import reuters#每次访问数据需要添加数据至路径当中data.path.append(r\"F:\\About-Python\\NLP_env_1\\note\\nltk_data\")files = reuters.fileids()print(files) 输出结果遇见问题级解决方案持续更新中","categories":[{"name":"NLP(自然语言处理)","slug":"NLP-自然语言处理","permalink":"http://yoursite.com/categories/NLP-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"}],"tags":[{"name":"NLP(自然语言处理)","slug":"NLP-自然语言处理","permalink":"http://yoursite.com/tags/NLP-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"}]},{"title":"python-math标准库的使用","slug":"python/python1","date":"2020-03-09T06:53:59.000Z","updated":"2020-03-09T07:20:42.215Z","comments":true,"path":"2020/03/09/python/python1/","link":"","permalink":"http://yoursite.com/2020/03/09/python/python1/","excerpt":"如何查看math标准库中的相关方法: 12import mathprint(dir(math)) 12345['__doc__', '__loader__', '__name__', '__package__', '__spec__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos', 'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs', 'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'gcd', 'hypot', 'inf', 'isclose', 'isfinite','isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'log2', 'modf', 'nan', 'pi', 'pow', 'radians', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'tau', 'trunc'] ps:结果的是以列表的形式呈现出来的","text":"如何查看math标准库中的相关方法: 12import mathprint(dir(math)) 12345['__doc__', '__loader__', '__name__', '__package__', '__spec__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos', 'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs', 'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'gcd', 'hypot', 'inf', 'isclose', 'isfinite','isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'log2', 'modf', 'nan', 'pi', 'pow', 'radians', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'tau', 'trunc'] ps:结果的是以列表的形式呈现出来的 库中方法分类(python3.6) 类别 个数 详情 三角函数类 13 cos(),cosh(),acos()acosh(),sin(),sinh(),asin(),asinh(),tan(),tanh(),atan(),atanh(),atan2() 常数类 3 pi,e,tau(2*pi) 常非数类 2 inf&lt;无穷&gt;,nan&lt;不是数&gt; 取整 3+1 ceil(),floor(),round()&lt;round()为python内置函数直接调用即可&gt;trunc()&lt;将小数部分直接砍掉&gt;–&gt;trunc(2.58585458678465)==2 is&lt;…&gt;判断函数 4 isclose(),isinf(),ifnan(),isfinite() 常规计算操作 7 求和:fsum();开方:sqrt();最小公约数:gcd();阶乘:factorial()模运算:fmod(x,y),modf()&lt;modf()展现小数部分&gt;绝对值:fabs(),abs() &lt;abs()为python内置函数直接调用&gt; 幂运算 6 exp(),frexp(),frex(),expm1(),pow(),ldexp(x,i)==x(2*i) 对数 4 log(),log10(),loglp(),log2() 魔法方法 5 &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39; 判断函数正确性 2 erf(),erfc() 复杂数学公式实现 5 gamma函数:gamma(),lgamma()计算三角形斜边函数:hypot()弧度,角度之间转换:degrees()&lt;弧-&gt;角&gt;,radians()&lt;角-&gt;弧&gt; 方法使用过程中的注意事项1.相同功能的函数其准确性的比较: exp(2) &gt; e**2 ; log10(x) &gt; log(x,10)2.相同功能函数其执行速度比较: abs(x) &gt; fabs(x) (x必须为数值型)3.python-math库 学习手册(官方资料) ps:整理过程中有不恰当的地方可以在下方留言(＾Ｕ＾)ノ~ＹＯ ?","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-09T04:42:24.128Z","updated":"2020-03-09T14:17:51.086Z","comments":true,"path":"2020/03/09/hello-world/","link":"","permalink":"http://yoursite.com/2020/03/09/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}